{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from FireSimulator import *\n",
    "from FireSimulatorUtilities import *\n",
    "import glob\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, w = x.size() \n",
    "        return x.view(N, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 50 sims from file\n",
      "for a total of 7066 states\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "pattern = os.path.join(directory,'states_seed_*')\n",
    "\n",
    "data = {}\n",
    "k = 0\n",
    "total_states = 0\n",
    "for file in glob.glob(pattern):\n",
    "    fh = open(file, 'rb')\n",
    "    sub_data = pickle.load(fh)\n",
    "    data[k] = sub_data\n",
    "    fh.close()\n",
    "    k += 1\n",
    "    total_states += sub_data.shape[0]\n",
    "    \n",
    "print('loaded %d sims from file' %(k))\n",
    "print('for a total of %d states' %(total_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network datatype [cpu/gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class eelfff_net(nn.Module):\n",
    "    \"\"\"\n",
    "    network to approximate Q function\n",
    "    \"\"\"\n",
    "    def __init__(self, act_seq=8, img_dim=8):\n",
    "        self.act_seq = act_seq\n",
    "        self.img_dim = img_dim\n",
    "        \n",
    "        C, H, W = 1, img_dim, img_dim\n",
    "        hidden_dim = 2048\n",
    "        \n",
    "        # conv layer settings\n",
    "        nf1 = 128; nf2 = 128\n",
    "        fs1 = 2; fs2 = 2\n",
    "        cv_s1 = 1; cv_s2 = 1\n",
    "        cv_p1 = 0; cv_p2 = 0\n",
    "        \n",
    "        # pool layer settings\n",
    "        p_sz1 = 4; p_sz2 = 2\n",
    "        p_st1 = 1; p_st2 = 1\n",
    "        \n",
    "        # calculate affine layer size\n",
    "        Hp1 = 1 + (H + 2*cv_p1 - fs1) // cv_s1\n",
    "        Wp1 = Hp1\n",
    "        Hpp1 = 1 + (Hp1 - p_sz1) // p_st1\n",
    "        Wpp1 = Hpp1\n",
    "        \n",
    "        Hp2 = 1 + (Hpp1 + 2*cv_p2 - fs2) // cv_s2\n",
    "        Wp2 = Hp2\n",
    "        Hpp2 = 1 + (Hp2 - p_sz2) // p_st2\n",
    "        Wpp2 = Hpp2\n",
    "        \n",
    "        #aff_flat_size = nf2*Hpp2*Wpp2 + 2*act_seq\n",
    "        aff_flat_size = nf1*Hpp1*Wpp1 + 2*(act_seq+1)\n",
    "        \n",
    "        super(eelfff_net, self).__init__()\n",
    "        # cnn structure\n",
    "        self.cnn = nn.Sequential(\n",
    "                        nn.Conv2d(C, nf1, kernel_size=fs1, stride=cv_s1, padding=cv_p1),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.MaxPool2d(p_sz1,stride=p_st1),\n",
    "                        #nn.Conv2d(nf1, nf2, kernel_size=fs2, stride=cv_s2, padding=cv_p2),\n",
    "                        #nn.ReLU(inplace=True),\n",
    "                        #nn.MaxPool2d(p_sz2,stride=p_st2),\n",
    "                        Flatten()\n",
    "                    )\n",
    "        \n",
    "        # nonlinear structure\n",
    "        self.aff = nn.Sequential(\n",
    "                        nn.Linear(aff_flat_size, hidden_dim),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(hidden_dim, 5*act_seq)\n",
    "                    )\n",
    "        \n",
    "    def forward(self, img, act):\n",
    "        img_exp = img.unsqueeze(1)\n",
    "        feat = self.cnn(img_exp)\n",
    "        feat = torch.cat((feat, act), dim=1)\n",
    "        Q = self.aff(feat)\n",
    "        \n",
    "        return Q.view(N,5,self.act_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test implementation of network with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 8])\n",
      "25.17s = 0.42m elapsed for this test\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "N = 4\n",
    "img_dim = 8\n",
    "act_seq = 8\n",
    "model = eelfff_net(img_dim, act_seq).type(dtype)\n",
    "\n",
    "img = torch.randn(N,img_dim,img_dim).type(dtype)\n",
    "act = torch.randn(N,2*(act_seq+1)).type(dtype)\n",
    "\n",
    "img_var = Variable(img)\n",
    "act_var = Variable(act)\n",
    "\n",
    "Q = model(img_var, act_var)\n",
    "toc = time.clock()\n",
    "\n",
    "print(Q.size())\n",
    "print(\"%0.2fs = %0.2fm elapsed for this test\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define a reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eelfff_reward(states, trajs, fire_flags, other_trajs):\n",
    "    N = states.shape[0]\n",
    "    grid_size = states[0].shape[0]\n",
    "    center = math.ceil(grid_size/2)\n",
    "    neighbors = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "    #reward = Variable(torch.zeros(1), requires_grad=True).type(dtype)\n",
    "    reward = 0\n",
    "    \n",
    "    for n in range(N):\n",
    "        st = states[n,:,:]\n",
    "        traj = trajs[n]\n",
    "        other_traj = other_trajs[n]\n",
    "        has_fires = fire_flags[n]\n",
    "        \n",
    "        # reward for treating fires and boundary fires\n",
    "        # that weren't already treated by the agent\n",
    "        if has_fires:\n",
    "            treated = []\n",
    "            for (x,y) in traj:\n",
    "                r = y_to_row(grid_size,y)\n",
    "                c = x_to_col(x)\n",
    "\n",
    "                # reward for treating a fire\n",
    "                if st[r,c] == 1 and (x,y) not in treated:\n",
    "                    reward += 1\n",
    "\n",
    "                    counter = 0 \n",
    "                    for (dc,dr) in neighbors:\n",
    "                        rn = r + dr\n",
    "                        cn = c + dc\n",
    "                        if rn>=0 and rn<grid_size and cn>=0 and cn<grid_size and st[rn,cn] == 0:\n",
    "                            counter += 1\n",
    "\n",
    "                    # bonus for treating a boundary fire\n",
    "                    if counter >= 2:\n",
    "                        reward += 4\n",
    "                        \n",
    "                    treated.append((x,y))\n",
    "           \n",
    "        # reward for approaching center [if no fires in image]\n",
    "        else:\n",
    "            for k in range(len(traj)-1):\n",
    "                x1, y1 = traj[k]\n",
    "                x2, y2 = traj[k+1]\n",
    "                if np.abs(x2-center)+np.abs(y2-center) < np.abs(x1-center)+np.abs(y1-center):\n",
    "                    reward += 1.0/(len(traj)-1)\n",
    "    \n",
    "        # penalty for intersecting with 'nearest agent'\n",
    "        if not set(traj).isdisjoint(other_traj):\n",
    "            reward += -2*len(set(traj).intersection(other_traj))            \n",
    "    \n",
    "    return reward/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test reward function with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch reward: 1.50\n",
      "0.00s = 0.00m elapsed for this test\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "\n",
    "states = np.zeros((3,5,5)).astype(np.uint8)\n",
    "states[:,2,2] = 1\n",
    "trajs = []\n",
    "trajs.append([(5,5),(5,5),(4,4)])\n",
    "trajs.append([(3,3),(3,3),(3,3)])\n",
    "trajs.append([(5,5),(4,4),(3,3)])\n",
    "other_trajs = []\n",
    "other_trajs.append([(1,1),(1,2),(1,1)])\n",
    "other_trajs.append([(1,1),(1,2),(1,3)])\n",
    "other_trajs.append([(1,1),(2,2),(3,3)])\n",
    "fire_flags = np.zeros(3, dtype=bool)\n",
    "fire_flags[1:-1] = True\n",
    "\n",
    "reward = eelfff_reward(states, trajs, fire_flags, other_trajs)\n",
    "print('minibatch reward: %0.2f' %reward)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed for this test\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulator and network parameters\n",
    "seeds = range(1)\n",
    "grid_size = 50\n",
    "num_agents = [2,5,10,25]\n",
    "D = []\n",
    "dp = 0.15/0.2763\n",
    "act_seq = 8\n",
    "img_dim = 8\n",
    "\n",
    "# agent initialization parameters\n",
    "spawn_loc = np.arange(grid_size//3//2,grid_size,grid_size//3)\n",
    "perturbs = np.arange(-grid_size//3//2+1,grid_size//3//2+1,1)\n",
    "\n",
    "# create network instance\n",
    "model = eelfff_net(act_seq=act_seq, img_dim=img_dim)\n",
    "model.train()\n",
    "\n",
    "# optimizer and its parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-0de3afe581cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m#print(all_healthy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m#plt.imshow(img, cmap='gray', vmin=0, vmax=255)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[1;36m5\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# add to replay memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# run simulator many times\n",
    "for s in seeds:\n",
    "    np.random.seed(s)\n",
    "    \n",
    "    # initialize simulator\n",
    "    sim = FireSimulator(grid_size, rng=s)\n",
    "    \n",
    "    # initialize agent positions\n",
    "    n = np.squeeze(np.random.choice(num_agents, 1))\n",
    "    agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "        \n",
    "    # run to termination\n",
    "    while not sim.end:\n",
    "        \n",
    "        control = []\n",
    "        new_agent_pos = np.zeros((n,2))\n",
    "        \n",
    "        # generate control\n",
    "        for i in range(n):\n",
    "            # generate image\n",
    "            img, img_st, all_hlthy = CreateImageBW(sim.state, agent_pos[i,:])\n",
    "            #print(all_healthy)\n",
    "            #plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "            \n",
    "            # find nearest neighbor and their trajectory\n",
    "            \n",
    "            # generate trajectory using network\n",
    "            \n",
    "            # find control from trajectory\n",
    "            \n",
    "            # add to replay memory\n",
    "            5/0\n",
    "        \n",
    "        # step simulator\n",
    "        sim.step(control, dbeta=dp)\n",
    "        \n",
    "        # update agent position\n",
    "        agent_pos = new_agent_pos\n",
    "        \n",
    "    # create minibatch from replay memory and update network\n",
    "    \n",
    "    # drop from memory if too many elements\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hlthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, 255, 255, 255, 255, 255],\n",
       "       [255,   0, 255, 255, 255, 255, 255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
