{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from datetime import datetime\n",
    "from FireSimulator import *\n",
    "from FireSimulatorUtilities import *\n",
    "import glob\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() \n",
    "        return x.view(N, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hand-tuned function to generate actions for agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heuristic(agent_id, pos, img_st, seen_fire, center, close_agent_id, close_pos):\n",
    "\n",
    "    traj = []\n",
    "    actions = []\n",
    "    traj.append((pos[0],pos[1]))\n",
    "    img_dim = img_st.shape[0]\n",
    "    fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "    move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "    action_set = [4,1,2,3,5,8,7,6]\n",
    "    \n",
    "    dists = None\n",
    "    x,y = pos\n",
    "\n",
    "    r = img_dim//2\n",
    "    c = img_dim//2\n",
    "\n",
    "    if img_st[r,c] in [1,2] or seen_fire:\n",
    "        seen_fire = True\n",
    "        dists = []\n",
    "        \n",
    "        cen_vec = np.array([x-center,y-center])\n",
    "        cen_vec = cen_vec/np.linalg.norm(cen_vec)\n",
    "        for a in range(1,9):\n",
    "        #for a in [2,5,7,4]:\n",
    "            new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "\n",
    "            rl = -new_pos[1] + y + img_dim//2\n",
    "            cl = new_pos[0] -x + img_dim//2\n",
    "            #if a in [1,3,8,6] and img_st[rl,cl] in [0]:\n",
    "            #    continue\n",
    "\n",
    "            move_vec = np.array([new_pos[0]-x,new_pos[1]-y])\n",
    "            if a != 0:\n",
    "                move_vec = move_vec/np.linalg.norm(move_vec)\n",
    "            dists.append((np.cross(cen_vec,move_vec),new_pos,a))\n",
    "\n",
    "        cir_pos = min(dists)[1]\n",
    "        cir_act = min(dists)[2]\n",
    "\n",
    "        ri = -cir_pos[1] + y + img_dim//2\n",
    "        ci = cir_pos[0] -x + img_dim//2\n",
    "\n",
    "        left_act = None\n",
    "        if cir_act==1:\n",
    "            left_act = [6,4]\n",
    "            #left_act = [4]\n",
    "            righ_act = [2]\n",
    "        elif cir_act==2:\n",
    "            left_act = [4,1]\n",
    "            #left_act = [1]\n",
    "            righ_act = [3]\n",
    "        elif cir_act==3:\n",
    "            left_act = [1,2]\n",
    "            #left_act = [2]\n",
    "            righ_act = [5]\n",
    "        elif cir_act==5:\n",
    "            left_act = [2,3]\n",
    "            #left_act = [3]\n",
    "            righ_act = [8]\n",
    "        elif cir_act==8:\n",
    "            left_act = [3,5]\n",
    "            #left_act = [5]\n",
    "            righ_act = [7]\n",
    "        elif cir_act==7:\n",
    "            left_act = [5,8]\n",
    "            #left_act = [8]\n",
    "            righ_act = [6]\n",
    "        elif cir_act==6:\n",
    "            left_act = [8,7]\n",
    "            #left_act = [7]\n",
    "            righ_act = [4]\n",
    "        elif cir_act==4:\n",
    "            left_act = [7,6]\n",
    "            #left_act = [6]\n",
    "            righ_act = [1]\n",
    "\n",
    "        '''\n",
    "        left_act = None\n",
    "        if cir_act==2:\n",
    "            #left_act = [3]\n",
    "            left_act = [1]\n",
    "        elif cir_act==5:\n",
    "            #left_act = [8]\n",
    "            left_act = [3]\n",
    "        elif cir_act==7:\n",
    "            #left_act = [6]\n",
    "            left_act = [8]\n",
    "        elif cir_act==4:\n",
    "            #left_act = [1]\n",
    "            left_act = [6]\n",
    "        '''    \n",
    "        #print(cir_act)\n",
    "        #print(left_act)\n",
    "\n",
    "        '''\n",
    "        out_pos = actions_to_trajectory(traj[-1],[left_act[0]])[1]\n",
    "        ro = -out_pos[1] + y + img_dim//2\n",
    "        co = out_pos[0] - x + img_dim//2\n",
    "        if img_st[ro,co] in [1,2]:\n",
    "            cir_pos = out_pos\n",
    "            cir_act = left_act[0]\n",
    "        elif img_st[ri,ci] in [0]:\n",
    "            cir_act = righ_act[0]\n",
    "            cir_pos = actions_to_trajectory(traj[-1],[cir_act])[1]\n",
    "        '''\n",
    "\n",
    "        out = False\n",
    "        for a in left_act:\n",
    "            new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "            ro = -new_pos[1] + y + img_dim//2\n",
    "            co = new_pos[0] - x + img_dim//2\n",
    "            if img_st[ro,co] in [1]:\n",
    "                cir_pos = new_pos\n",
    "                cir_act = a\n",
    "                out = True\n",
    "                break\n",
    "\n",
    "        if not out:\n",
    "            for a in left_act:\n",
    "                new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                ro = -new_pos[1] + y + img_dim//2\n",
    "                co = new_pos[0] - x + img_dim//2\n",
    "                if img_st[ro,co] in [2]:\n",
    "                    cir_pos = new_pos\n",
    "                    cir_act = a\n",
    "                    out = True\n",
    "                    break\n",
    "\n",
    "        counter = 0\n",
    "        for (dr,dc) in move_neigh:\n",
    "            rn = ri + dr\n",
    "            cn = ci + dc\n",
    "            if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] in [0]:\n",
    "                counter += 1\n",
    "\n",
    "        if not out and img_st[ri,ci] in [0] and counter>=6:\n",
    "            for a in righ_act:\n",
    "                new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                cir_pos = new_pos\n",
    "                cir_act = a\n",
    "\n",
    "        if np.linalg.norm(cir_pos-close_pos,2)<=1 and agent_id > close_agent_id:\n",
    "            cir_pos = traj[-1]\n",
    "            cir_act = 0\n",
    "\n",
    "        traj.append(cir_pos)\n",
    "        actions.append(cir_act)      \n",
    "\n",
    "    if not seen_fire:\n",
    "        dists = []\n",
    "        #for a in range(9):\n",
    "        for idx,a in enumerate([2,5,7,4,1,3,8,6]):\n",
    "            new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "            incntv = -(8-idx)*0.1\n",
    "            dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1])+incntv,new_pos,a))\n",
    "\n",
    "        #print(dists)\n",
    "        #print()\n",
    "        score, pos, act = min(dists)\n",
    "        traj.append(pos)\n",
    "        actions.append(act)\n",
    "        \n",
    "    return traj, actions, seen_fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test heuristic in simulator [qualitatively]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "img_dim = 8\n",
    "act_repeat = 6\n",
    "center = (grid_size+1)/2\n",
    "dp = 0.15/0.2763\n",
    "\n",
    "# agent initialization parameters\n",
    "spawn_loc = np.arange(grid_size//3//2,grid_size,grid_size//3)\n",
    "perturbs = np.arange(-grid_size//3//2+1,grid_size//3//2+1,1)\n",
    "\n",
    "num_agents = 10\n",
    "seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plotting = True\n",
    "\n",
    "tic = time.clock()\n",
    "# set rng seed\n",
    "s = seed\n",
    "np.random.seed(s)\n",
    "\n",
    "# initialize simulator\n",
    "sim = FireSimulator(grid_size, rng=s)\n",
    "sim.step([])\n",
    "\n",
    "# initialize agent positions\n",
    "# n = np.squeeze(np.random.choice(num_agents, 1))\n",
    "n = num_agents\n",
    "agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "agent_pos = agent_pos.astype(np.int32)\n",
    "\n",
    "control = []\n",
    "repeat_cntr = 1\n",
    "agent_sf = {}\n",
    "for k in range(n):\n",
    "    agent_sf[k] = False\n",
    "\n",
    "# run simulation\n",
    "#while not sim.end:\n",
    "for _ in range(150):\n",
    "    if plotting:\n",
    "        plt.figure()\n",
    "        plt.grid()\n",
    "        plt.xlim([0,grid_size+1])\n",
    "        plt.ylim([0,grid_size+1])\n",
    "        plt.title('iteration: %d, action: %d' % (sim.iter,repeat_cntr))\n",
    "\n",
    "        #plt.plot(center,center,\"gx\")\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                x = col_to_x(j)\n",
    "                y = row_to_y(grid_size,i)\n",
    "                if sim.state[i,j] == 1:\n",
    "                    plt.plot(x,y,\"rs\",alpha=0.6)\n",
    "                elif sim.state[i,j] == 2:\n",
    "                    plt.plot(x,y,\"ks\",alpha=0.6)\n",
    "\n",
    "    new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "\n",
    "    # generate control for each agent\n",
    "    for k in range(n):\n",
    "        # generate image\n",
    "        img, img_st, hasfire = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "\n",
    "        # generate action and resulting trajectory using heuristic\n",
    "        dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i,pos) for i,pos in enumerate(agent_pos) if i!=k]\n",
    "        min_dist, min_id, min_pos = min(dists)\n",
    "        traj, act, sf = heuristic(k, agent_pos[k,:], img_st, agent_sf[k], center, min_id, min_pos)\n",
    "        agent_sf[k] = sf\n",
    "\n",
    "        # generate control from trajectory\n",
    "        control.extend(FindGridIntersections(sim.state, traj))\n",
    "\n",
    "        #if k == 0:\n",
    "            #print(img_st)\n",
    "        if plotting:\n",
    "            plt.plot(traj[0][0],traj[0][1],\"bo\")\n",
    "            plt.plot(traj[-1][0],traj[-1][1],\"bx\")\n",
    "        #for (x,y) in traj:\n",
    "        #    plt.plot(x,y,\"bo\")\n",
    "\n",
    "        #for (x,y) in other_traj:\n",
    "        #    plt.plot(x,y,\"b^\")\n",
    "\n",
    "        # store agent's new position\n",
    "        new_agent_pos[k,:] = [traj[-1][0], traj[-1][1]]\n",
    "\n",
    "    # remove duplicates from control sequence\n",
    "    control = list(set(control))\n",
    "\n",
    "    # step simulator\n",
    "    #sim.step(control, dbeta=dp)\n",
    "    if repeat_cntr % act_repeat == 0:\n",
    "        sim.step(control, dbeta=dp)\n",
    "        control = []\n",
    "        repeat_cntr = 1\n",
    "    else:\n",
    "        repeat_cntr += 1\n",
    "\n",
    "    # update agent position\n",
    "    agent_pos = new_agent_pos\n",
    "\n",
    "    if plotting:\n",
    "        #plt.legend(['%d' %(len(set(tuple(x) for x in agent_pos)))])\n",
    "        plt.plot(center,center,\"ys\",label='# unique agents = %d' %(len(set(tuple(x) for x in agent_pos))))\n",
    "        plt.legend()\n",
    "\n",
    "    #if sim.end:\n",
    "    #    print('breaking early because game ended')\n",
    "    #    break\n",
    "\n",
    "    #if len(set(tuple(x) for x in agent_pos)) < n:\n",
    "    #    print('agents merged!')\n",
    "    #    #plt.plot(23,24,\"yo\")\n",
    "    #    break\n",
    "\n",
    "print(\"episode stats: %s, %f\" %(sim.stats,sim.stats[0]/np.sum(sim.stats)))\n",
    "print('# unique agents left = %d' %(len(set(tuple(x) for x in agent_pos))))\n",
    "        \n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark heuristic solution by running many simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_agents = 10\n",
    "seeds = range(100)\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic = time.clock()\n",
    "# run many simulations\n",
    "for i,s in enumerate(seeds):\n",
    "    np.random.seed(s)\n",
    "\n",
    "    # initialize simulator\n",
    "    sim = FireSimulator(grid_size, rng=s)\n",
    "    sim.step([])\n",
    "\n",
    "    # initialize agent positions\n",
    "    # n = np.squeeze(np.random.choice(num_agents, 1))\n",
    "    n = num_agents\n",
    "    agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "    agent_pos = agent_pos.astype(np.int32)\n",
    "\n",
    "    control = []\n",
    "    repeat_cntr = 1\n",
    "    agent_sf = {}\n",
    "    for k in range(n):\n",
    "        agent_sf[k] = False\n",
    "\n",
    "    # run simulation\n",
    "    while not sim.end:\n",
    "    #for _ in range(6*6):\n",
    "    \n",
    "        new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "\n",
    "        # generate control for each agent\n",
    "        for k in range(n):\n",
    "            # generate image\n",
    "            img, img_st, hasfire = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "\n",
    "            # generate action and resulting trajectory using heuristic\n",
    "            dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i,pos) for i,pos in enumerate(agent_pos) if i!=k]\n",
    "            min_dist, min_id, min_pos = min(dists)\n",
    "            traj, act, sf = heuristic(k, agent_pos[k,:], img_st, agent_sf[k], center, min_id, min_pos)\n",
    "            agent_sf[k] = sf\n",
    "\n",
    "            # generate control from trajectory\n",
    "            control.extend(FindGridIntersections(sim.state, traj))\n",
    "\n",
    "            # store agent's new position\n",
    "            new_agent_pos[k,:] = [traj[-1][0], traj[-1][1]]\n",
    "\n",
    "        # remove duplicates from control sequence\n",
    "        control = list(set(control))\n",
    "\n",
    "        # step simulator\n",
    "        #sim.step(control, dbeta=dp)\n",
    "        if repeat_cntr % act_repeat == 0:\n",
    "            sim.step(control, dbeta=dp)\n",
    "            control = []\n",
    "            repeat_cntr = 1\n",
    "        else:\n",
    "            repeat_cntr += 1\n",
    "\n",
    "        # update agent position\n",
    "        agent_pos = new_agent_pos\n",
    "\n",
    "    #print(\"[seed %3d] episode stats: %s, %f\" %(s,sim.stats,sim.stats[0]/np.sum(sim.stats)))\n",
    "    #print('# unique agents left = %d' %(len(set(tuple(x) for x in agent_pos))))\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(\"finished %d simulations\" % (i+1))\n",
    "    \n",
    "    # store simulation result\n",
    "    results.append(sim.stats[2]/np.sum(sim.stats)) # fraction of burned trees\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "weights = np.ones_like(results)/float(len(results))\n",
    "plt.hist(results, bins=np.arange(0,1+0.05,0.05), normed=False, weights=weights)\n",
    "plt.axvline(np.mean(results),color=\"C1\",label=\"mean\")\n",
    "plt.axvline(np.percentile(results,0),color=\"C2\",label=\"min\")\n",
    "plt.axvline(np.percentile(results,100),color=\"C3\",label=\"max\")\n",
    "\n",
    "plt.xticks(np.arange(0,1+0.05,0.05))\n",
    "plt.xlabel('fraction of forest burned down')\n",
    "plt.ylabel('normalized count')\n",
    "plt.title('grid size: %d; number of agents: %d\\nnumber of simulations: %d' %(grid_size,num_agents,len(results)))\n",
    "# plt.legend(loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eelfff_reward(agent_id, traj, seen_fire, img_st, center, close_agent_id, close_pos):\n",
    "    reward = 0\n",
    "    fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "    img_dim = img_st.shape[0]\n",
    "    \n",
    "    x1,y1 = traj[0]\n",
    "    x2,y2 = traj[1]\n",
    "    \n",
    "    r = -y2 + y1 + img_dim//2\n",
    "    c = x2 - x1 + img_dim//2\n",
    "    \n",
    "    if img_st[r,c] in [1,2]:\n",
    "        counter = 0\n",
    "        for (dr,dc) in fire_neigh:\n",
    "            rn = r + dr\n",
    "            cn = c + dc\n",
    "            if img_st[rn,cn]==0:\n",
    "                counter += 1\n",
    "        \n",
    "        if counter > 0:\n",
    "            reward += 0.1\n",
    "        else:\n",
    "            reward += -1      \n",
    "            #print('didnt move to a boundary node!')\n",
    "    \n",
    "    elif not seen_fire:\n",
    "        if np.abs(x2-center)+np.abs(y2-center) < np.abs(x1-center)+np.abs(y1-center):\n",
    "            reward += 0.1\n",
    "        else:\n",
    "            reward += -1\n",
    "            #print('didnt move closer to center!')\n",
    "            \n",
    "    if np.linalg.norm(traj[1]-close_pos,2) <= 1 and agent_id > close_agent_id:\n",
    "        reward += -1      \n",
    "        #print('failed to cooperate!')\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test reward function with heuristic solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_agents = 10\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 26 simulation steps:\n",
      "average reward: 0.14\n",
      "episode stats: [2391   15   94], 0.956400\n",
      "# unique agents left = 10\n",
      "0.81s = 0.01m elapsed\n"
     ]
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "plotting = False\n",
    "\n",
    "tic = time.clock()\n",
    "# set rng seed\n",
    "s = seed\n",
    "np.random.seed(s)\n",
    "\n",
    "# initialize simulator\n",
    "sim = FireSimulator(grid_size, rng=s)\n",
    "sim.step([])\n",
    "\n",
    "# initialize agent positions\n",
    "# n = np.squeeze(np.random.choice(num_agents, 1))\n",
    "n = num_agents\n",
    "agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "agent_pos = agent_pos.astype(np.int32)\n",
    "\n",
    "ep_rew = 0\n",
    "control = []\n",
    "repeat_cntr = 1\n",
    "agent_sf = {}\n",
    "for k in range(n):\n",
    "    agent_sf[k] = False\n",
    "\n",
    "# run simulation\n",
    "#while not sim.end:\n",
    "for _ in range(150):\n",
    "    if plotting:\n",
    "        plt.figure()\n",
    "        plt.grid()\n",
    "        plt.xlim([0,grid_size+1])\n",
    "        plt.ylim([0,grid_size+1])\n",
    "        plt.title('iteration: %d, action: %d' % (sim.iter,repeat_cntr))\n",
    "\n",
    "        #plt.plot(center,center,\"gx\")\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                x = col_to_x(j)\n",
    "                y = row_to_y(grid_size,i)\n",
    "                if sim.state[i,j] == 1:\n",
    "                    plt.plot(x,y,\"rs\",alpha=0.6)\n",
    "                elif sim.state[i,j] == 2:\n",
    "                    plt.plot(x,y,\"ks\",alpha=0.6)\n",
    "\n",
    "    new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "\n",
    "    # generate control for each agent\n",
    "    for k in range(n):\n",
    "        # generate image\n",
    "        img, img_st, hasfire = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "\n",
    "        # generate action and resulting trajectory using heuristic\n",
    "        dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i,pos) for i,pos in enumerate(agent_pos) if i!=k]\n",
    "        min_dist, min_id, min_pos = min(dists)\n",
    "        traj, act, sf = heuristic(k, agent_pos[k,:], img_st, agent_sf[k], center, min_id, min_pos)\n",
    "        agent_sf[k] = sf\n",
    "        \n",
    "        # calculate agent reward\n",
    "        reward = eelfff_reward(k, traj, sf, img_st, center, min_id, min_pos)\n",
    "        ep_rew += reward\n",
    "\n",
    "        # generate control from trajectory\n",
    "        control.extend(FindGridIntersections(sim.state, traj))\n",
    "\n",
    "        #if k == 0:\n",
    "            #print(img_st)\n",
    "        if plotting:\n",
    "            plt.plot(traj[0][0],traj[0][1],\"bo\")\n",
    "            plt.plot(traj[-1][0],traj[-1][1],\"bx\")\n",
    "        #for (x,y) in traj:\n",
    "        #    plt.plot(x,y,\"bo\")\n",
    "\n",
    "        #for (x,y) in other_traj:\n",
    "        #    plt.plot(x,y,\"b^\")\n",
    "\n",
    "        # store agent's new position\n",
    "        new_agent_pos[k,:] = [traj[-1][0], traj[-1][1]]\n",
    "\n",
    "    # remove duplicates from control sequence\n",
    "    control = list(set(control))\n",
    "\n",
    "    # step simulator\n",
    "    #sim.step(control, dbeta=dp)\n",
    "    if repeat_cntr % act_repeat == 0:\n",
    "        sim.step(control, dbeta=dp)\n",
    "        control = []\n",
    "        repeat_cntr = 1\n",
    "    else:\n",
    "        repeat_cntr += 1\n",
    "\n",
    "    # update agent position\n",
    "    agent_pos = new_agent_pos\n",
    "\n",
    "    if plotting:\n",
    "        #plt.legend(['%d' %(len(set(tuple(x) for x in agent_pos)))])\n",
    "        plt.plot(center,center,\"ys\",label='# unique agents = %d' %(len(set(tuple(x) for x in agent_pos))))\n",
    "        plt.legend()\n",
    "\n",
    "    #if sim.end:\n",
    "    #    print('breaking early because game ended')\n",
    "    #    break\n",
    "\n",
    "    #if len(set(tuple(x) for x in agent_pos)) < n:\n",
    "    #    print('agents merged!')\n",
    "    #    #plt.plot(23,24,\"yo\")\n",
    "    #    break\n",
    "\n",
    "print(\"after %d simulation steps:\" %(sim.iter))\n",
    "print(\"average reward: %0.2f\" %(ep_rew/(n*sim.iter)))\n",
    "print(\"episode stats: %s, %f\" %(sim.stats,sim.stats[0]/np.sum(sim.stats)))\n",
    "print('# unique agents left = %d' %(len(set(tuple(x) for x in agent_pos))))\n",
    "        \n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fit a network to the heuristic solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class eelfff_net(nn.Module):\n",
    "    \"\"\"\n",
    "    network to approximate Q function\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dim=8):\n",
    "        self.img_dim = img_dim\n",
    "        self.num_poss_actions = 9\n",
    "        \n",
    "        C, H, W = 1, img_dim, img_dim\n",
    "        hidden_dim = 2048\n",
    "        \n",
    "        # conv layer settings\n",
    "        nf1 = 32; nf2 = 64; nf3 = 64;\n",
    "        fs1 = 4; fs2 = 3; fs3 = 2;\n",
    "        cv_s1 = 1; cv_s2 = 1; cv_s3 = 1;\n",
    "        cv_p1 = 0; cv_p2 = 0; cv_p3 = 0;\n",
    "        \n",
    "        # pool layer settings\n",
    "        #p_sz1 = 4; p_sz2 = 2\n",
    "        #p_st1 = 1; p_st2 = 1\n",
    "        \n",
    "        # calculate affine layer size\n",
    "        Hp1 = 1 + (H + 2*cv_p1 - fs1) // cv_s1\n",
    "        Wp1 = Hp1\n",
    "        #Hpp1 = 1 + (Hp1 - p_sz1) // p_st1\n",
    "        #Wpp1 = Hpp1\n",
    "        \n",
    "        Hp2 = 1 + (Hp1 + 2*cv_p2 - fs2) // cv_s2\n",
    "        Wp2 = Hp2\n",
    "        #Hpp2 = 1 + (Hp2 - p_sz2) // p_st2\n",
    "        #Wpp2 = Hpp2\n",
    "        \n",
    "        Hp3 = 1 + (Hp2 + 2*cv_p3 - fs3) // cv_s3\n",
    "        Wp3 = Hp3        \n",
    "        \n",
    "        #aff_flat_size = nf2*Hpp2*Wpp2 + 2*act_seq\n",
    "        # image + id + position + seen_fire + center + close_id + close_pos\n",
    "        aff_flat_size = nf3*Hp3*Wp3 + 1 + 2 + 1 + 2 + 1 + 2\n",
    "        \n",
    "        #print(Hp1)\n",
    "        #print(Hp2)\n",
    "        #print(Hp3)\n",
    "        \n",
    "        super(eelfff_net, self).__init__()\n",
    "        # cnn structure\n",
    "        self.cnn = nn.Sequential(\n",
    "                        nn.Conv2d(C, nf1, kernel_size=fs1, stride=cv_s1, padding=cv_p1),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(nf1, nf2, kernel_size=fs2, stride=cv_s2, padding=cv_p2),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(nf2, nf3, kernel_size=fs3, stride=cv_s3, padding=cv_p3),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        #nn.MaxPool2d(p_sz1,stride=p_st1),\n",
    "                        #nn.Conv2d(nf1, nf2, kernel_size=fs2, stride=cv_s2, padding=cv_p2),\n",
    "                        #nn.ReLU(inplace=True),\n",
    "                        #nn.MaxPool2d(p_sz2,stride=p_st2),\n",
    "                        Flatten()\n",
    "                    )\n",
    "        \n",
    "        # nonlinear structure\n",
    "        self.aff = nn.Sequential(\n",
    "                        nn.Linear(aff_flat_size, hidden_dim),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        #nn.Linear(hidden_dim, self.num_poss_actions*act_seq),\n",
    "                        nn.Linear(hidden_dim, self.num_poss_actions)\n",
    "                    )\n",
    "        \n",
    "    def forward(self, img, ide, pos, sf, center, close_ide, close_pos):\n",
    "        img_exp = img.unsqueeze(0)\n",
    "        img_exp = img_exp.unsqueeze(0)\n",
    "        ide_exp = ide.unsqueeze(0)\n",
    "        pos_exp = pos.unsqueeze(0)\n",
    "        sf_exp = sf.unsqueeze(0)\n",
    "        cen_exp = center.unsqueeze(0)\n",
    "        cid_exp = close_ide.unsqueeze(0)\n",
    "        cpo_exp = close_pos.unsqueeze(0)\n",
    "        \n",
    "        feat = self.cnn(img_exp)\n",
    "        feat = torch.cat((feat, ide_exp, pos_exp, sf_exp, cen_exp, cid_exp, cpo_exp), dim=1)\n",
    "\n",
    "        Q = self.aff(feat)\n",
    "        \n",
    "        #return Q.view(N,self.num_poss_actions,self.act_seq)\n",
    "        return Q.view(N,self.num_poss_actions,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test architecture with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 1])\n",
      "458.89s = 7.65m elapsed for this test\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "N = 1\n",
    "img_dim = 8\n",
    "model = eelfff_net(img_dim).type(dtype)\n",
    "\n",
    "img = Variable(torch.randn(img_dim,img_dim).type(dtype))\n",
    "ide = Variable(torch.ones(1).type(dtype))\n",
    "pos = Variable(torch.randn(2).type(dtype))\n",
    "sf = Variable((True*torch.ones(1)).type(dtype))\n",
    "center = Variable(torch.randn(2).type(dtype))\n",
    "cid = Variable(2*torch.ones(1)).type(dtype)\n",
    "cpo = Variable(torch.randn(2).type(dtype))\n",
    "\n",
    "Q = model(img, ide, pos, sf, center, cid, cpo)\n",
    "toc = time.clock()\n",
    "\n",
    "print(Q.size())\n",
    "print(\"%0.2fs = %0.2fm elapsed for this test\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network by running simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulator and network parameters\n",
    "grid_size = 50\n",
    "num_agents = [2,5,10]\n",
    "D = []\n",
    "memory_size = 1000000 #1000000\n",
    "min_exp_size = 5000 #100\n",
    "dp = 0.15/0.2763\n",
    "act_repeat = 6\n",
    "img_dim = 8\n",
    "center = (grid_size+1)/2\n",
    "cen_var = Variable(center*torch.ones(2)).type(dtype)\n",
    "\n",
    "# agent initialization parameters\n",
    "spawn_loc = np.arange(grid_size//3//2,grid_size,grid_size//3)\n",
    "perturbs = np.arange(-grid_size//3//2+1,grid_size//3//2+1,1)\n",
    "\n",
    "# create network instance\n",
    "model = eelfff_net(img_dim=img_dim).type(dtype)\n",
    "target = eelfff_net(img_dim=img_dim).type(dtype)\n",
    "updt_max = 1000 #500\n",
    "dqn_updt_cntr = 1\n",
    "\n",
    "# optimizer and its parameters\n",
    "gamma = 0.99\n",
    "batch_size = 32\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2.5e-4, betas=(0.95,0.95), eps=0.01)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# plotting data\n",
    "plot_avg_rew = []\n",
    "plot_frac_burn = []\n",
    "plot_loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seeds = range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 000 - average reward: 0.25\n",
      "           episode stats: [  27    0 2473], 0.010800\n",
      "49.86s = 0.83m elapsed\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "# run simulator many times\n",
    "for i,s in enumerate(seeds):\n",
    "    np.random.seed(s)\n",
    "    \n",
    "    # initialize simulator\n",
    "    sim = FireSimulator(grid_size, rng=s)\n",
    "    sim.step([])\n",
    "    \n",
    "    # initialize agent positions\n",
    "    n = np.squeeze(np.random.choice(num_agents, 1))\n",
    "    agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "    agent_pos = agent_pos.astype(np.int32)\n",
    "    \n",
    "    ep_rew = 0\n",
    "    control = []\n",
    "    repeat_cntr = 1\n",
    "    agent_sf = {}\n",
    "    for k in range(n):\n",
    "        agent_sf[k] = False\n",
    "        \n",
    "    # run to termination\n",
    "    while not sim.end:\n",
    "        \n",
    "        #control = []\n",
    "        new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "        agent_data = {}\n",
    "        \n",
    "        # generate control for each agent\n",
    "        for k in range(n):\n",
    "            agent_data[k] = {}\n",
    "            agent_data[k]['id'] = Variable(k*torch.ones(1)).type(dtype)\n",
    "            agent_data[k]['pos'] = Variable(torch.from_numpy(agent_pos[k,:])).type(dtype)\n",
    "            agent_data[k]['sf'] = Variable(agent_sf[k]*torch.ones(1)).type(dtype)\n",
    "            \n",
    "            # generate and save image\n",
    "            img, img_st, _ = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "            agent_data[k]['img'] = Variable(torch.from_numpy(img)).type(dtype)\n",
    "\n",
    "            # find nearest neighbor and their position, and save it\n",
    "            dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i,pos) for i,pos in enumerate(agent_pos) if i != k]\n",
    "            _, min_id, min_pos = min(dists)\n",
    "            agent_data[k]['other_id'] = Variable(min_id*torch.ones(1)).type(dtype)\n",
    "            agent_data[k]['other_pos'] = Variable(torch.from_numpy(min_pos)).type(dtype)\n",
    "            \n",
    "            # always use heuristic to generate and save actions\n",
    "            traj, act, sf = heuristic(k, agent_pos[k,:], img_st, agent_sf[k], center, min_id, min_pos)\n",
    "            agent_sf[k] = sf\n",
    "            agent_data[k]['act'] = act \n",
    "            agent_data[k]['next_sf'] = Variable(sf*torch.ones(1)).type(dtype)\n",
    "            \n",
    "            # generate control from trajectory\n",
    "            control.extend(FindGridIntersections(sim.state, traj))\n",
    "\n",
    "            # calculate and store reward for agent\n",
    "            reward = eelfff_reward(k, traj, sf, img_st, center, min_id, min_pos)\n",
    "            agent_data[k]['reward'] = reward\n",
    "            ep_rew += reward\n",
    "                        \n",
    "            # store agent's new position\n",
    "            new_agent_pos[k,:] = [traj[-1][0], traj[-1][1]]\n",
    "\n",
    "            \n",
    "        # remove duplicates from control sequence\n",
    "        control = list(set(control))\n",
    "        \n",
    "        # step simulator\n",
    "        if repeat_cntr % act_repeat == 0:\n",
    "            sim.step(control, dbeta=dp)\n",
    "            control = []\n",
    "            repeat_cntr = 1\n",
    "        else:\n",
    "            repeat_cntr += 1\n",
    "                    \n",
    "        # update agent position\n",
    "        agent_pos = new_agent_pos\n",
    "        \n",
    "        # grab new state information and add to replay memory\n",
    "        isterminal = False\n",
    "        for k in range(n):\n",
    "            # generate and save image\n",
    "            next_img, _, _ = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "            agent_data[k]['next_img'] = Variable(torch.from_numpy(next_img)).type(dtype)\n",
    "            agent_data[k]['next_pos'] = Variable(torch.from_numpy(agent_pos[k,:])).type(dtype)\n",
    "            \n",
    "            # find nearest neighbor and their trajectory\n",
    "            dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i,pos) for i,pos in enumerate(agent_pos) if i != k]\n",
    "            _, min_id, min_pos = min(dists)\n",
    "            agent_data[k]['next_other_id'] = Variable(min_id*torch.ones(1)).type(dtype)\n",
    "            agent_data[k]['next_other_pos'] = Variable(torch.from_numpy(min_pos)).type(dtype)\n",
    "            \n",
    "            # check for terminal state\n",
    "            if sim.end:\n",
    "                isterminal = True\n",
    "                \n",
    "            D.append((agent_data[k]['img'],agent_data[k]['id'],agent_data[k]['pos'],agent_data[k]['sf'],\n",
    "                      agent_data[k]['other_id'],agent_data[k]['other_pos'],\n",
    "                      agent_data[k]['act'],agent_data[k]['reward'],\n",
    "                      agent_data[k]['next_img'],agent_data[k]['next_pos'],agent_data[k]['next_sf'],\n",
    "                      agent_data[k]['next_other_id'],agent_data[k]['next_other_pos'],\n",
    "                      isterminal))\n",
    "                \n",
    "        # create minibatch from replay memory\n",
    "        loss = 0\n",
    "        if len(D) < min_exp_size:\n",
    "            continue\n",
    "\n",
    "        batch_idxs = np.random.randint(0,high=len(D),size=batch_size)\n",
    "\n",
    "        # calculate loss over batch\n",
    "        # exp indices: 0-img, 1-id, 2-pos, 3-seen_fire, 4-other_id, 5-other_pos, \n",
    "        #              6-action, 7-reward, \n",
    "        #              8-next_img, 9-next_pos, 10-next_seen_fire, 11-next_other_id, 12-next_other_pos\n",
    "        #              13-isterminal\n",
    "        for idx in batch_idxs:\n",
    "            exp = D[idx]\n",
    "            # reward clipping\n",
    "            #curr_rew = np.clip(exp[5],-5,5)\n",
    "            curr_rew = exp[7]\n",
    "            tt = Variable(curr_rew*torch.ones(1),requires_grad=False).type(dtype)\n",
    "            \n",
    "            img = exp[0]\n",
    "            ide = exp[1]\n",
    "            pos = exp[2]\n",
    "            sf = exp[3]\n",
    "            cid = exp[4]\n",
    "            cpo = exp[5]\n",
    "            actions = exp[6]\n",
    "            \n",
    "            Q = model(img, ide, pos, sf, cen_var, cid, cpo)[0]\n",
    "            x = Q[torch.FloatTensor(actions).type(torch.cuda.LongTensor)]\n",
    "            #x = Q[torch.from_numpy(actions)].diag().sum()\n",
    "            \n",
    "            isterminal = exp[13]\n",
    "            if not isterminal:\n",
    "                next_img = exp[8]\n",
    "                next_pos = exp[9]\n",
    "                next_sf = exp[10]\n",
    "                next_cid = exp[11]\n",
    "                next_cpo = exp[12]\n",
    "\n",
    "                Q = target(next_img, ide, next_pos, next_sf, cen_var, next_cid, next_cpo)[0]\n",
    "                maxQ = Q.max(dim=0)[0].sum()\n",
    "                tt += Variable(gamma*maxQ.data, requires_grad=False).type(dtype)\n",
    "            \n",
    "            # error clipping\n",
    "            #loss += (loss_fn(x, tt)).clamp(min=-5,max=5)\n",
    "            loss += loss_fn(x, tt)\n",
    "\n",
    "        loss /= batch_size\n",
    "        plot_loss_hist.append(loss.data[0])\n",
    "\n",
    "        # update network\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping\n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), 0.5) \n",
    "        #for param in model.parameters():\n",
    "        #    param.grad.data.clamp_(-1,1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update target network, if appropriate\n",
    "        if dqn_updt_cntr % updt_max == 0:\n",
    "            target = copy.deepcopy(model)\n",
    "            dqn_updt_cntr = 1\n",
    "        else:\n",
    "            dqn_updt_cntr += 1\n",
    "        \n",
    "        # drop from memory if too many elements\n",
    "        if len(D) > memory_size:\n",
    "            D = D[len(D)-memory_size:]\n",
    "            \n",
    "    avg_rew = ep_rew/(n*sim.iter)\n",
    "    frac_burn = sim.stats[0]/np.sum(sim.stats)\n",
    "    print(\"seed %03d - average reward: %0.2f\" %(s,avg_rew))\n",
    "    print(\"           episode stats: %s, %f\" %(sim.stats,frac_burn))\n",
    "    \n",
    "    plot_avg_rew.append(avg_rew)\n",
    "    plot_frac_burn.append(frac_burn)\n",
    "        \n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb48732fe48>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAHkCAYAAACNG88nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm0XXV9///nO4mBkDDKUCEQEBGlSgUiQhERhRasBqqo\nTBaUQQgkKt/2VxzaWlDbQrWamzBEwiTIJA5BRkEmQTRhSkiYYmQIoAwyJpCQ5P37Y5/AIeTm7Htz\nz93nnPt8rHVWsvfZe59X2q7VN5/P/rw/kZlIkiRJPTWo6gCSJElqTxaSkiRJ6hULSUmSJPWKhaQk\nSZJ6xUJSkiRJvWIhKUmSpF6xkJQkSWonEWcS8SQR93TzfRAxgYg5RMwgYvtmRbGQlCRJai9nA3ut\n5Pu9ga1qnyOBU5sVxEJSkiSpnWTeBPxlJVfsA5xLZpJ5G7AOEW9rRhQLSUmSpM6yCfBo3fG82rk+\nN6QZD201gwYNymHDhlUdQ5IkqaElCxbkK3BH3anJZE6uLNBKDIhCctiwYcyfP7/qGJIkSQ1FxMtk\njl6FRzwGbFp3PLJ2rs85tS1JktRZpgL/VFu9vRPwPJlPNOOHBsSIpCRJUseIuAD4MLA+EfOA/wDe\nAkDmacAVwMeAOcAC4PNNi5KZzXp2yxg+fHg6tS1JktpBRCzIzOFV5yjDqW1JkiT1ioWkJEmSesVC\nUpIkSb1iISlJkqResZCUJElSr1hISpIkqVcsJCVJktQrFpKSJEnqFQtJSZIk9YqFpCRJknrFQlKS\nJEm9YiEpSZKkXrGQlCRJWonzz4fNN4dBg4o/zz+/6kStY0jVASRJklrV+efDkUfCggXF8cMPF8cA\nBx1UXa5WEZlZdYamGz58eM6fP7/qGJIkqc1svnlRPC5v1Ch46KHm/GZELMjM4c15et+ykJQkSerG\noEGwolIpApYubc5vtlMh6TuSkiRJ3dhss56dH2gsJCVJkrrx7W/D4MFvPLfGGsV5WUhKkiR1a5dd\nYMkSWGutYjp71CiYPNmFNsu4aluSJKkbp5xSjEjOmgUjR1adpvU4IilJkrQCCxbAGWfAJz9pEdkd\nC0lJkqQVOP98ePZZGDeu6iSty/Y/kiRJy8mEbbeFIUPgjjuK9yP7Szu1//EdSUmSpOXceCPccw9M\nmdK/RWS7cWpbkiRpORMmwFvfCgccUHWS1mYhKUmSVOfhh+EXv4AjjoBhw6pO09osJCVJkuqcckox\nnX300VUnaX0WkpIkSTXLWv7su6/bIJZhISlJklTz4x/DX/4C48dXnaQ9NLWQjGCvCO6PYE4Ex6/g\n++MimB3BjAiui2BU3XdLIrir9plad36LCH5Xe+ZFEQxt5r9BkiQNDJnQ1VW0/dl116rTtIemFZIR\nDAYmAXsD2wAHRLDNcpfdCYzOZFvgJ8BJdd+9nMn7ap8xdef/B/i/TN4BPAsc1qx/gyRJGjhuuglm\nzChGI235U04zRyR3BOZkMjeTRcCFwD71F2RyfSYLaoe3ASvdgCiCAD5CUXQCnAPs26epJUnSgNTV\nBeutBwceWHWS9tHMQnIT4NG643m1c905DLiy7nj1CKZHcFvEa8XiW4HnMllc8pmSJEkNPfII/Oxn\ntvzpqZbY2SaCg4HRwG51p0dl8lgEbwd+HcFM4PkePPNI4EiAob5FKUmSVuLUU4s/bfnTM80ckXwM\n2LTueGTt3BtEsAfwdWBMJguXnc8srs1kLnADsB3wDLBOxGsF8AqfWbtvciajMxk9pCXKZUmS1Ipe\nfhkmTy5a/owa1fh6va6ZheQ0YKvaKuuhwP7w+uprgAi2A06nKCKfrDu/bgSr1f6+PrALMDuTBK4H\n9qtdegjwiyb+GyRJUoe74IKi5c+4cVUnaT+Rmc17ePAx4PvAYODMTL4dwQnA9EymRnAt8F7gidot\nj2QyJoK/pSgwl1IUu9/PZErtmW+nWLizHsWq74PrRzJXZPjw4Tl//vwm/AslSVI7y4TttoOlS+Hu\nu1tjtXZELMjM4VXnKKOphWSrsJCUJEkrcvPN8KEPFVPbRxxRdZpCOxWS7mwjSZIGrAkTYN114aCD\nqk7SniwkJUnSgPToo0XLn8MPhzXWqDpNe7KQlCRJA9KppxbvSI4dW3WS9mUhKUmSBpxlLX/GjIHN\nN686TfuykJQkSQPOhRfCM88U+2qr91y1LUmSBpRM2GEHePVVmDGjNVr+1GunVdvu+SJJkgaUW26B\nO++E009vvSKy3Ti1LUmSBpSuLlhnHVv+9AULSUmSNGDMmweXXlq0/BneFpPHrc1CUpIkDRinnVZs\nh2jLn75hISlJkgaEV14p3oscMwa22KLqNJ3BQlKSJA0IF10ETz8N48ZVnaRz2P5HkiR1vEwYPboY\nlbznntZerW37H0mSpBby29/CHXcU2yK2chHZbpzaliRJHW/CBFh7bfjc56pO0lksJCVJUkd77LGi\n5c9hh9nyp69ZSEqSpI522mmwZAkcc0zVSTqPi20kSVLHWrgQNt0UdtoJpk6tOk057bTYxhFJSZLU\nsS66CJ56CsaPrzpJZ3JEUpIkdaRMeP/7YcECmDWrfVZrt9OIpO1/JElSR7rtNrj9djjllPYpItuN\nU9uSJKkjdXXZ8qfZLCQlSVLHefxxuOQS+MIXYMSIqtN0LgtJSZLUcU4/3ZY//cHFNpIkqaMsXAib\nbQY77giXXVZ1mp5rp8U2jkhKkqSOcskl8OSTMG5c1Uk6nyOSkiSpo+y4I7z4Isye3Z6rtR2RlCRJ\nqsDvfgfTpsGxx7ZnEdluLCQlSVLHmDAB1loL/umfqk4yMFhISpKkjvDEE8X7kZ//PKy5ZtVpBgYL\nSUmS1BFOPx0WLy6mtdU/XGwjSZLa3qJFRcufHXaAyy+vOs2qcbGNJElSP7rkEvjzn2H8+KqTDCyO\nSEqSpLa3007w7LNw770wqM2HyRyRlCRJ6ie//33R9ufYY9u/iGw3/o9bkiS1ta6uYpX2IYdUnWTg\nsZCUJElt609/gosugkMPLfpHqn9ZSEqSpLY1eTK8+qotf6riYhtJktSWFi2CUaPgfe+DK6+sOk3f\ncbGNJElSk116aTG1bcuf6lhISpKktjRhAmy1Ffz931edpJ9F7EXE/UTMIeL4FXy/GRHXE3EnETOI\n+FizolhISpKktjNtGtx22wBs+RMxGJgE7A1sAxxAxDbLXfUN4GIytwP2B05pVpyB9D96SZLUIbq6\nYMSIYrX2ALMjMIfMuWQuAi4E9lnumgSWrWFfG3i8WWGGNOvBkiRJzfDnPxctf448ckC2/NkEeLTu\neB7wgeWu+SZwDRHjgOHAHs0K44ikJElqK5MnFyu2O7Xlz/owhIjpdZ8je/iIA4CzyRwJfAz4ERFN\nqfmaWkhGsFcE90cwJ4I3vQwawXERzI5gRgTXRTBque/XimBeBBPrzh0QwczaPVdFsH4z/w2SJKl1\nvPoqnHpqscBm662rTtMcT8NiMkfXfSbXff0YsGnd8cjauXqHARcDkPlbYHVoTr3UtEIygje9DBrB\n8i+D3gmMzmRb4CfASct9fyJwU90zhwA/AHav3TMD6ND/HpEkScu79FJ44gkYN67qJJWZBmxFxBZE\nDKVYTDN1uWseAT4KQMS7KQrJp5oRppkjkjsCczKZm8kKXwbN5PpMFtQOb6OoqgGIYAdgI+Caului\n9hkeQVC8SNq0F0glSVJr6eqCLbeEvfeuOklFMhdTDKJdDdxLsTp7FhEnEDGmdtX/A44g4m7gAuBQ\nmrQDTTMX25R5GbTeYcCVABEMAr4LHEzdC6KZvBrB0cBMYD7wIHBM38aWJEmt6Pbb4dZb4f/+b4C1\n/Fle5hXAFcud+/e6v88GdumPKC3xv4YIDgZGAyfXTo0Frshk3nLXvQU4GtgO2Jhiavur3TzzyAim\nRzB98eKmRZckSf2kqwuGD4fPf77qJFqmmSOSZV4GJYI9gK8Du2WysHZ6Z2DXCMYCI4ChEbwEXAqQ\nyR9q914Mb17EU7tmMjAZYPhwOn9DcUmSOtiTT8IFF8Dhh8Paa1edRss0s5CcBmwVwRYUBeT+wIH1\nF0SwHXA6sFcmTy47n8lBddccSrEg5/gINga2iWCDTJ4C9qR4P0CSJHWwH/6ws1v+tKumFZKZLI54\n7WXQwcCZmcyK4ARgeiZTKaayRwCXRADwSCZjVvLMxyP4T+CmCF4FHgYObda/QZIkVW9Zy58994R3\nv7vqNKoXTVrE01KGDx+e8+fPrzqGJEnqhYsvhs9+Fi67DD7+8arTNF9ELMjM4VXnKMNCUpIktbRd\nd4XHH4cHHoDBg6tO03ztVEi2xKptSZKkFbnzTvjNb4p3IwdCEdluLCQlSVLL6uqCNdaw5U+rspCU\nJEkt6amn4Mc/hkMOgXXWqTqNVsRCUpIktaQzzoCFC23508pcbCNJklrO4sWwxRbwrnfBr35VdZr+\n1U6LbZrZkFySJKlXfv5zmDcPJk2qOolWxhFJSZLUcj70oaKQfPDBgbdau51GJH1HUpIktZS77oKb\nb4Zjjhl4RWS7sZCUJEktZVnLny98oeokasRCUpIktYynny5a/nzuc7DuulWnUSMWkpIkqWWccQa8\n8gqMG1d1EpVRarFNRHwS+CCQwG8y82fNDtaXXGwjSVLrW7wY3v522GoruO66qtNUp6MW20TEKcBR\nwEzgHuCLEeFifEmS1Kd+8Qt49FEYP77qJCqr4YhkRNwHvDtrF0bEIGBWZr67H/L1CUckJUlqfR/+\nMDz8MMyZM7BXa3fUiCQwB9is7njT2jlJkqQ+MWMG3HijLX/aTZmdbdYE7o2I31O8I7kjMD0ipgJk\n5pgm5pMkSQNAVxcMG2bLn3ZTppD896ankCRJA9Yzz8B558E//ROst17VadQTDQvJzLwxIkYBW2Xm\ntRExDBiSmS82P54kSep0U6YULX+OPbbqJOqpMqu2jwB+ApxeOzUS+HkzQ0mSpIFh8WKYNAl23x3e\n+96q06inyiy2OQbYBXgBIDMfBDZsZihJkjQwXHYZPPKIDcjbVZlCcmFmLlp2EBFDKBbdSJIkrZIJ\nE2DUKPjEJ6pOot4oU0jeGBFfA4ZFxJ7AJcBlzY0lSZI63cyZcMMNMHYsDCmz/Fctp0wheTzwFMXO\nNl8ErsjMrzc1lSRJ6njLWv4cfnjVSdRbZer/cZn5A+CHy05ExJdq5yRJknrsL38pWv4cdJAtf9pZ\nmRHJQ1Zw7tA+ziFJkgaQKVPg5ZddZNPuut1rOyIOAA4EPgjcXPfVWsCSzPxo8+P1DffaliSpdSxZ\nAltuCZtvXrwjqTdqp722Vza1fSvwBLA+8N268y8CM5oZSpIkda7LLoOHH4bvfa/qJFpV3Y5IvnZB\nxHDg5cxcGhHvBN4FXJmZr/ZHwL7giKQkSa3jox+FBx+EuXNdrb0i7TQiWeYdyZuA1SNiE+Aa4HPA\n2c0MJUmSOtM998Cvfw3HHGMR2QnKFJKRmQuATwKnZOangb9ubixJktSJJk6E1Ve35U+nKFVIRsTO\nwEHA5bVzg5sXSZIkdaJnn4Uf/aho+fPWt1adRn2hTCH5JeCrwM8yc1ZEvB24vrmxJElSpznzTFiw\nwJY/naThYptO4GIbSZKqtWQJvOMdsNlmcOONVadpbZ222EaSJGmVXH45PPSQo5GdxhFJSZLUdHvs\nAfffD3/8o6u1G+mYEcmIGBwRX+mvMJIkqfPMng3XXQdjx1pEdpqVFpKZuQQ4oJ+ySJKkDtTVBaut\nBkccUXUS9bUy/11wS0RMBC4CXpsfzsw7mpZKkiR1hOeeg3PPhQMPhPXXrzqN+lqZQvJ9tT9PqDuX\nwEf6Po4kSeoktvzpbC62kSRJTbFkCbzznbDxxnDzzVWnaR8ds9gGICI2iogpEXFl7XibiDis+dEk\nSVI7u+IKmDsXxo+vOomapUwfybOBq4GNa8cPAF9uViBJktQZurpgk01g332rTqJmKVNIrp+ZFwNL\nATJzMbCkqakkSVJbu/de+NWvipY/b3lL1WnULGUKyfkR8VaKBTZExE7A801NJUmS2trEibb8GQjK\nFJLHAVOBLSPiFuBcoNTaqwj2iuD+COZEcPwKvj8ugtkRzIjgughGLff9WhHMi2Bi3bmhEUyO4IEI\n7ovgU2WySJKk/vH883DOOXDAAbDBBlWnUTM1bP+TmXdExG7A1kAA92fmq43ui2AwMAnYE5gHTItg\naiaz6y67ExidyYIIjgZOAj5b9/2JwE3LPfrrwJOZvDOCQcB6jbJIkqT+c9ZZMH++LX8GgoaFZESs\nDowFPkgxvX1zRJyWma80uHVHYE4mc4vncCGwD7xeSGZyfd31twEHv/677ABsBFwFjK677gvAu2r3\nLwWebvRvkCRJ/WPp0mJae5ddYPvtq06jZisztX0u8NdAFzCx9vcflbhvE+DRuuN5tXPdOQyotRhi\nEPBd4J/rL4hgndpfT4zgjgguiWCjElkkSVI/uPJK+MMfHI0cKMrsbPOezNym7vj6iJjd7dW9EMHB\nFKOOu9VOjQWuyGRexBsuHQKMBG7N5LgIjgP+F/jcCp55JHAkwNChfZlWkiR1Z8KEogH5Jz9ZdRL1\nhzKF5B0RsVNm3gYQER8Appe47zFg07rjkbVzbxDBHhTvPe6WycLa6Z2BXSMYC4wAhkbwEvBVYAHw\n09p1l1CMZL5JJpOByQDDh9P52/dIklSx++6Da66BE0+05c9AUaaQ3AG4NSIeqR1vBtwfETOBzMxt\nu7lvGrBVBFtQFJD7AwfWXxDBdsDpwF6ZPLnsfCYH1V1zKMWCnONrx5cBHwZ+DXwU6NPRUUmS1DsT\nJxazgEceWXUS9ZcyheRevXlwJosjOJZiV5zBwJmZzIrgBGB6JlOBkylGHC+pTWE/ksmYBo/+V+BH\nEXwfeAr4fG/ySZKkvrOs5c/++8OGG1adRv0lMjt/1nf48OE5f/78qmNIktSxfvAD+PKXYdo0GD26\n8fXqXkQsyMzhVecow0JSkiStkqVLYeuti+bjt95adZr2106FZJn2P5IkSd266iqYM8eWPwNRw0Iy\nIv6nzDlJkjQwdXXB294Gn3LT4gGnzIjknis4t3dfB5EkSe3n/vuLEcmjjrJv80DU7artiDiaojH4\n2yNiRt1XawK3NDuYJElqfZMmFT0jv/jFqpOoCt0utomItYF1gf+CoodjzYuZ+Zd+yNZnXGwjSVLf\ne+EF2GQT2Hdf+FGZzZNVSjsttul2RDIznweeBw6IiMHARrXrR0TEiMx8pLt7JUlS5zvnHHjpJRg/\nvuokqkrD9j8RcSzwTeDPwNLa6ZXtaNNyHJGUJKlvLV0K73oXrLce3HZb1Wk6S5UjkhExCBiRmS+U\nub7MzjZfBrbOzGdWKZkkSeoY11wDDz4I559fdRKtqoj4MXAUsIRii+u1IuIHmXlyo3vLrNp+lGKK\nW5IkCYAJE+Cv/gr226/qJOoD29RGIPcFrgS2AD5X5sYyI5JzgRsi4nJg4bKTmfm9XgSVJElt7sEH\n4cor4ZvftOVPh3hLRLyFopCcmJmvRkSprQ/LFJKP1D5Dax9JkjSA2fKn45wOPATcDdwUEaOAUu9I\nlt5rOyLWyMwFvU1YJRfbSJLUN158sWj5M2YMnHde1Wk6Uyu0/4mIIZm5uNF1ZbZI3DkiZgP31Y7/\nJiJO6YOMkiSpzZx7blFMuq9254iIjSJiSkRcWTveBjikzL1lFtt8H/h74BmAzLwb+FAvs0qSpDa1\ndGmxr/aOO8IHPlB1GvWhs4GrgY1rxw9QdO1pqEwhSWY+utypJWWTSZKkznDttcXe2o5Gdpz1M/Ni\nav3Ca1PapWq9MottHo2IvwWytqLnS8C9vU0qSZLa04QJsNFG8OlPV51EfWx+RLwVSICI2ImSrR/L\nFJJHAT8ANgEeA64BjuldTkmS1I7mzIErroB/+zdYbbWq06iPHQdMBbaMiFuADYBSHUJLr9puZ67a\nliRp1XzlKzBxIjzyCLztbVWn6WxVrNqOiCHA1kAA92fmq2XuazgiGRETVnD6eWB6Zv6iRyklSVLb\neeklOPPMYkrbIrIFROxFMVs8GDiDzP9ewTWfAb5JMV19N5kHdv+4WINiVHJUZh4REVtFxNaZ+ctG\nUcostlkdeB/wYO2zLTASOCwivl/ifkmS1MbOPRdeeAHGj686iYgYDEwC9ga2AQ6gaNdTf81WwFeB\nXcj8axqvwD4LWATsXDt+DPhWmThl3pHcFtglM5cU2eJU4Gbgg8DMMj8iSZLaU2bR8mf0aFv+tIgd\ngTlkzgUg4kJgH2B23TVHAJPIfBaAzCcbPHPLzPxsRBxQXJ4LIiLKhCkzIrkuMKLueDiwXq2wXLji\nWyRJUie49lq4775iNLJcaaEm2wSob8s4r3au3juBdxJxCxG31abCV2ZRRAzj9VXbW1KyxiszInkS\ncFdE3EDxAuaHgO9ExHDg2jI/IkmS2lNXF2y4IXzmM1UnGTjWhyFETK87NZnMyT14xBBgK+DDFK8j\n3kTEe8l8rpvr/wO4Ctg0Is4HdgEOLftDK5WZUyLiCoqhVICvZebjtb//S5kfkSRJ7WfuXPjlL+Eb\n37DlT396GhaTObqbrx8DNq07Hlk7V28e8DuKldd/JOIBisJy2vIPq01h3wd8EtiJYtDwS5n5dJms\npXa2AV4BngCeBd4REW6RKElSh5s0CQYPhqOOqjqJ6kwDtiJiCyKGAvtT9ICs93OK0UiIWJ9iqnvu\nih6WRR/IKzLzmcy8PDN/WbaIhHLtfw6n2M1mJHAXRbX6W+AjZX9EkiS1l5degilTYL/9YOONG1+v\nfpK5mIhjKfbGHgycSeYsIk4AppM5tfbd3xExm2Krw38h85mVPPWOiHh/Zr5pxLKRhg3JI2Im8H7g\ntsx8X0S8C/hOZn6ypz9WFRuSS5LUM6edBkcfDbfcAn/7t1WnGVj6uyF5RNwHvAN4GJhPMb2dmblt\no3vLLLZ5JTNfiQgiYrXMvC8itl61yJIkqVUta/mzww6w886Nr1fb+/ve3limkJwXEetQzLf/KiKe\npahYJUlSB/r1r2H2bDj7bFv+DBDfyszP1Z+IiB8Bn+vm+tev68le2xGxG7A2cFVmLuppyqo4tS1J\nUnn77AO//W2xr/bqq1edZuCpYGr7jszcvu54MDAzM7dZyW1AuRHJ12Tmjb3IJ0mS2sQf/wiXXQZf\n+5pFZKeLiK8CXwOGRcQLy05TbJdYqm9l2fY/kiRpAJg0CQYNKhbaqLNl5n9l5prAyZm5Vu2zZma+\nNTO/WuYZPZrabldObUuS1Nj8+TByJPzd38FFF1WdZuDq76ntVbHSEcmIGBwR1/dXGEmSVJ3zzoPn\nniv21ZbKWGkhmZlLgKURsXY/5ZEkSRVY1vJnu+3sG6nyyiy2eQmYGRG/omhSCUBm+t8rkiR1iOuv\nh1mz4KyzbPkz0ETEd4EzM3NWT+8tU0j+tPaRJEkdqqsL1l8f9t+/6iSqwL3A5IgYApwFXJCZz5e5\nsdRim4gYBmyWmfevUsyKuNhGkqTuPfQQbLklHH88fPvbVadRVYttajsXfh44ALgF+GFmrnStTMP2\nPxHxCeAu4Kra8fsiYuqqx5UkSa3glFOK6Wxb/gxctSbk76p9ngbuBo6LiAtXel+jEcmIuB34CHBD\nZm5XO3dPZr6nL4L3B0ckJUlasQULipY/e+wBF19cdRpBJTvb/B/wCeA6YEpm/r7uu/szc+vu7i3z\njuSrmfl8vPHN26W9DStJklrH+efDs8/CuHFVJ1GFZgDfyMwVjbrtuLIby4xITqGoUI8HPgWMB96S\nmUf1Lmv/c0RSkqQ3y4Rtt4UhQ+COO1yt3SqqeEcyIjYBRlE3yJiZNzW6r8yI5Djg68BC4ALgauDE\n3sWUJEmt4sYb4Z57YMoUi8iBLCL+G9gfmA0sqZ1OoGEhWXqLxIhYC8jMfLGXOSvjiKQkSW/2yU/C\nTTfBo4/CsGFVp9EyFbwjeT+wbWYu7Om9ZVZtvz8iZlLMn8+MiLsjYodywdgrgvsjmBPB8Sv4/rgI\nZkcwI4LrIhi13PdrRTAvgokruHdqBPeUySFJkt7o4YfhF7+AI46wiBRzgbf05sYyU9tTgLGZeTNA\nRHyQolnltiu7KYLBwCRgT2AeMC2CqZnMrrvsTmB0JgsiOBo4Cfhs3fcnsoJh1Qg+SbHjjiRJ6gVb\n/igiuiimsBcAd0XEdRSvMgLldjEsU0guWVZE1h76m4hYXOK+HYE5mcwtwnIhsA+8XkhmUt/k8jbg\n4GUHEewAbETRv3J03fkRwHHAkYCNCiRJ6qEFC+CMM2DffWGzzapOowpNr/15O7B8j/BS7z6WKSRv\njIjTKRbaJMWI4Q0RsT1AZt7RzX2bAI/WHc8DPrCS3zkMuBIggkHAdykKyz2Wu+7E2ncLSmSXJEnL\n+fGP4S9/gfENx5vUyTLzHICI+FJm/qD+u4j4UplnlCkk/6b2538sd347isLyI2V+aGUiOJhi1HG3\n2qmxwBWZzKtfRRbB+4AtM/lKBJs3eOaRFKOWDB26qgklSeoMmcW+2ttuC7vuWnUatYhDgB8sd+7Q\nFZx7k4aFZGbu3rtMPAZsWnc8snbuDSLYg6K90G6Zr83L7wzsGsFYYAQwNIKXgIeB0RE8VMu+YQQ3\nZPLhN+dmMjAZYPjwcsOzkiR1uptughkziqltW/4MbBFxAHAgsMVy21+vCfyl1DPKtv/pqQiGAA8A\nH6UoIKcBB2Yyq+6a7YCfAHtl8mA3zzmUYkHOscud3xz4ZSYNt2q0/Y8kSYX99oPrr4d581yt3ar6\nq/1PRIwCtgD+C97QXedFYEZmNlwTU2Zqu1cyWRzBsRQNzAcDZ2YyK4ITgOmZTAVOphhxvKT2X0WP\nZDKmWZkkSRrIHnkEfvYz+Jd/sYgUZObDFLO9O/f2GU0bkWwljkhKkgRf/SqcdBLMnQujRjW+XtXo\nxxHJF1nx6uyg2IRmrUbP6PGIZESMBh7PzMd7eq8kSarGyy/D5MlFyx+LSAFk5pqr+ozeTG2PA7aN\niAcy87MNr5YkSZW74IKi5c+4cVUnUauKiA2B1ZcdZ+YjDe/p7dR2RKzZLvtuO7UtSRrIMmG77WDp\nUrj7bldmJqpDAAAgAElEQVRrt7oK9toeQ9Gje2PgSWAUcG9m/nWje7sdkVzWcLw7K2lELkmSWshv\nflMUkJMnW0RqhU4EdgKuzcztImJ36nYbXJmVTW1/t/bn6hTNwu+mePlyW4otdXq9wkeSJPWfCRNg\n3XXhoIOqTqIW9WpmPhMRgyJiUGZeHxHfL3Njt4XkskbkEfFTYPvMnFk7fg/wzT4ILUmSmuzRR4uW\nP8cdB2usUXUatajnImIEcDNwfkQ8CZR6J3BQiWu2XlZEAmTmPcC7exVTkiT1q1NPLd6RHDu26iRq\nYfsAC4AvA1cBfwA+UebGMqu2Z0bEGcB5teODgBm9CClJkvrRspY/Y8bA5ptXnUatKjPn13a52Soz\nz4mINSg2k2mozIjkocAs4Eu1z2zg873MKkmS+smFF8Izz8D48VUnUSuLiCMotqw+vXZqE+Dnpe5d\nWfufiBgMnJuZbf16ru1/JEkDTSbssAO8+irMmOFq7XZSQfufu4Adgd9l5na1czMz872N7l3piGRm\nLgFGRcTQPkkqSZL6xS23wJ13Fg3ILSLVwMLMXLTsICKGsOKtE9+kzDuSc4FbImIqdSt4MvN7PU0p\nSZL6R1cXrLOOLX9Uyo0R8TVgWETsCYwFLitzY5l3JP8A/LJ27Zp1H0mS1ILmzYNLL4XDDoPh/TZB\nqjZ2PPAUMBP4InAF8I0yN/Z6i8R24juSkqSB5BvfgO98B/7wB9hii6rTqKf6+x3JVdFwajsiNgD+\nP+CveeNG3h9pYi5JktQLr7wCp58On/iERaTKiYhdKDabGUVRGwaQmfn2RveWeUfyfOAi4OPAUcAh\nFMOfkiSpxVx0ETz9tC1/1CNTgK8AtwNLenJjw6ntiLg9M3eIiBmZuW3t3LTMfH9v0/Y3p7YlSQNB\nJoweXYxK3nOPq7XbVQXtf36XmR/ozb1lRiRfrf35RET8A/A4sF5vfkySJDXPb38Ld9xRbItoEalG\nImL72l+vj4iTgZ8CC5d9n5l3NHxGiRHJj1Ns4r0p0AWsBfxnZk7tZe5+54ikJGkg2H9/uOqqYtX2\niBFVp1Fv9deIZERcv5Kvs8x6mDKF5OqZ+UpPw7USC0lJUqd77LFiP+3x4+G73606jVZFR63aBu6J\niD9TjEreDPwmM59vbixJktQTp50GS5bAMcdUnUQDSak+khGxGbArsAvwMeC5zHxfk7P1GUckJUmd\nbOFC2HRT2GknmNo2L56pO+00ItlwZ5uIGElRQO4KbAfMomgHJEmSWsBFF8FTTxX7aktlRcSna3/2\nuuNomXcklwLTgO9k5i96+0NVckRSktSpMuH974cFC2DWLFdrd4J+XGxzR2Zuv+zP3jyjzDuS2wEf\nBA6MiOOBB4EbM3NKb35QkiT1ndtug9tvh0mTLCLVY89ExDXAFhHxppciMnNMoweUfUdyBEUxuStw\ncO3ho3octyKOSEqSOtWBB8Lllxertm350xn6cURyKLA98CPg8OW/z8wbGz2jzF7b04HVgFspVm1/\nKDMf7nFaSZLUpx5/HC65BI491iJSPZeZi4DbIuJvM/Op2sAhmflS2WeUmdreOzPdW1uSpBZz+um2\n/FGf2Kg2xb0eEBHxFHBIZt7T6MaGq7aBQRExJSKupHj6NhFx2KrllSRJq2LhwqKQ/NjH4B3vqDqN\n2txk4LjMHJWZmwH/r3auoTKF5NnA1cDGteMHgC/3IqQkSeojl1wCf/5zsZONtIqGZ+Zr2yVm5g1A\nqXc0yxSS62fmxcDS2sMXA0t6EVKSJPWRri7YemvYY4+qk6gDzI2If4uIzWufbwBzy9xYppCcHxFv\nBRIgInYC3CJRkqSK/O538PvfFw3IB5X5/+TSyn0B2AD4KXApsH7tXENlGpJvD3QB7wHuqf3Qfpk5\nYxUC9yvb/0iSOsnBBxdbIT72GKy5ZtVp1NfaaYvEla7ajohBwOrAbsDWQAD3Z+ar/ZBNkiQt509/\ngosvhrFjLSJVvZUWkpm5NCImZeayPbYlSVKFTj8dXn3Vlj9qDWXerLguIj4V4cZLkiRVadEiOO20\nouXPVltVnUYq15D8i8BxwOKIeIViejszc62mJpMkSW/wk58UU9vjxlWdRJ0kIjYAjgA2p642zMyG\nC25K7bXd7lxsI0nqBDvtBM8+C/fe62rtTtbfi20iYtk22LdT1+IxMy9tdG+ZEUlJklSx3/++aPsz\nYYJFpPrcGpn5r7250f9TlCSpDXR1Fau0Dzmk6iTqQL+MiI/15kantiVJanF/+hNsthkcdVQxIqnO\nVsHU9osUWyIuApa1eCy1HqbU1HZEfBDYKjPPqr2QOSIz/9jbwJIkqbzJk4uWP8ceW3USdaLM7HVH\n0jI72/wHMBrYOjPfGREbA5dk5i69/dH+5oikJKldLVoEm28Of/M3cOWVVadRf6hiZ5uIGAN8qHZ4\nQ2b+ssx9Zd6R/EdgDDAfIDMfB+ylL0lSP7j0UnjiCRg/vuok6lQR8d/Al4DZtc+XIuK/ytxbZmp7\nUWZmRGTtx9pi70dJkjpBV1fRfPzv/77qJOpgHwPel5lLASLiHOBO4KuNbiwzInlxRJwOrBMRRwDX\nAj8skyqCvSK4P4I5ERy/gu+Pi2B2BDMiuC6CUct9v1YE8yKYWDteI4LLI7gvglkR/HeZHJIktaPp\n0+G3vy3ejbTlj5psnbq/r132poYjkpn5vxGxJ/ACsDXw75n5q0b3RTAYmATsCcwDpkUwNZPZdZfd\nCYzOZEEERwMnAZ+t+/5E4KblHv2/mVwfwVDgugj2zsS3RiRJHaerC0aMgEMPrTqJOtx/AXdGxPUU\nOxh+CN48ALgipVZt1wrHhsXjcnYE5mQyFyCCC4F94PVCMpPr666/DTh42UEEOwAbAVdRLPYhkwVQ\n3JPJogjuAEb2MJckSS3vySfhwgvhyCNhLTclVhNl5gURcQPw/tqpf83MP5W5t9uB8oh4MSJe6O5T\n4tmbAI/WHc+rnevOYVCMLEYwCPgu8M/d52Md4BPAdSWySJLUViZPLlZs2/JHzRIR76r9uT3wNopa\nbR6wce1cQ92OSC7rKRQRJwJPAD+iGO48qPZjfSaCgylGHXernRoLXJHJvIgVXj8EuACYsGzEcwXX\nHAkcCTB0aF+mlSSpuV59FU49tVhgs/XWVadRBzuOolb67gq+S+AjjR5QZmp7TGb+Td3xqRFxN/Dv\nDe57DNi07nhk7dwbRLAH8HVgt0wW1k7vDOwawVhgBDA0gpcyX5uvnww8mMn3u/vxTCbXrmP4cDp/\n+x5JUsf46U/h8ceLUUmpWTLzyNpf987MV+q/i4jVyzyjzBqw+RFxUEQMjohBEXEQtZ6SDUwDtopg\ni9rCmP2BqW8MyXbA6cCYTJ5cdj6TgzLZLJPNKaa3z11WREbwLYrVRF8ukUGSpLYzYQJsuSXsvXfV\nSTRA3Fry3JuUKSQPBD4D/Bl4Evh07dxKZbIYOBa4GrgXuDiTWRGcEMGY2mUnU4w4XhLBXRFvLDSX\nF8FIitHLbYA7avccXuLfIElSW7j9drj1Vlv+aCUi9iLifiLmENH96uqITxGRRIxe8dfxVxGxAzAs\nIraLiO1rnw8Da5SK0miLxE7gFomSpHZx6KHwk5/AY4/B2qW7+amTrHSLxIjBwAPUtVcEDiBz9nLX\nrQlcDgwFjiVz+gp+5xDgUIp1KtMo1sJA0fLxnMz8aaOsDf9bJyJGRsTPIuLJ2ufSiLDljiRJfezJ\nJ+GCC+CQQywi1a0dgTlkziVzEbzWXnF5JwL/A7yygu8AyMxzMnN34NDM/Ehm7l777FOmiIRyU9tn\nUbzbuHHtc1ntnCRJ6kM//KEtf9RQ4/aKReueTcm8vOQzd4iI13a2iYh1I+JbZW4sU0hukJlnZebi\n2udsYIOSwSRJUgnLWv7suSe8+91Vp1GV1ochREyv+xzZ+K6aiEHA94D/14Of3Dszn1t2kJnPUuy/\n3VCZ9j/PRMTBFH0bAQ4AnulBOEmS1MDPfla8F3naaVUnUdWehsVkrnCBDI3bK64JvAe4gaIZ918B\nU4kYs6L3JGsGR8RqmbkQICKGAauVydpwsU1EjAK6KHo7AtwCjM/MR8r8QCtwsY0kqdXtumvRO/KB\nB2Dw4KrTqEoNFtsMoVhs81GKAnIacCCZs7q5/gbgn1dSRBIR/0qxW+CyVxc/D0zNzJMaZW04IpmZ\nD8Nr7XokSVIfu/NO+M1v4Hvfs4hUA5mLiVjWXnEwcCaZs4g4AZhO5kpbKa74kfk/ETGDojgFODEz\nry5zb5kRyZOAbwEvA1cB2wJfyczzehq0Ko5ISpJa2Re+ABddVExtr7NO4+vV2VY6Itliyiy2+bvM\nfAH4OPAQ8A7gX5oZSpKkgeKpp+DHPy5a/lhEqgoRsVNETIuIlyJiUUQsiYgXytxbppBcNv39D8Al\nmfl8r5NKkqQ3OOMMWLjQlj+q1ESKxdQPAsOAw4FJZW4sU0j+MiLuA3YArouIDVhJc0tJklTO4sVw\nyimwxx6wzTZVp9FAlplzgMGZuSQzzwL2KnNfmcU2x9fek3w+M5dExHxW3EFdkiT1wM9/DvPmwaRS\nYz9S0yyIiKHAXbWa7wnKDTZ2v9gmIj6Smb+OiE+u6PuyW+e0AhfbSJJa0Yc+VBSSDz7oam29rr8X\n29RaPf6ZYl/urwBrA6fURilXamUjkrsBv6boK7S8BNqmkJQkqdXcdRfcfDP87/9aRKo6ETEY+E5m\nHkTx6uJ/9uj+Ru1/OoEjkpKkVnPYYXDhhcWI5LrrVp1GraSCEcnfAB/JzEU9vbfhO5IR8VbgP4AP\nUoxE/gY4ITPdJlGSpF54+unXW/5YRKoFzAVuiYipwGsjb5n5vUY3lnmR8kLgKeBTwH61v1/Uu5yS\nJOmMM+CVV2DcuKqTSAD8AfglRV24Zt2noTI729yTme9Z7tzMzHxv77L2P6e2JUmtYvFiePvbYaut\n4Lrrqk6jVtRfU9sR8aPM/FxEfCkzf9CbZ5QZkbwmIvaPiEG1z2co9neUJEk99ItfwKOPwvjxVSeR\n2CEiNga+EBHrRsR69Z8yDygzIvkiMBxYSvGO5GBenz/PzFyr9/n7hyOSkqRW8eEPw8MPw5w5rtbW\nivXjiOR44Gjg7cBjQNR9nZn59kbPKNOQvNQcuSRJWrkZM+DGG+Hkky0iVb3MnABMiIhTM/Po3jyj\n4dR2FA6OiH+rHW8aETv25sckSRrIurpg2DD4wheqTiK9rrdFJJR7R/IUYGfgwNrxS5TcyFuSJBWe\neQbOOw8+9zlYr9TbZ1Lrazi1DXwgM7ePiDsBMvPZ2n6MkiSppClTipY/xx5bdRKp75QZkXy1tn1O\nAkTEBhQLbyRJUgmLF8OkSbD77vDetmmeJzVWppCcAPwM2DAivk2xs813mppKkqQOctll8MgjNiBX\n5ym113ZEvAv4KMWy8Osy895mB+tLtv+RJFVp993hj38sWv4MKfNSmQa0/t5re1WU+j/nzLwPuK/J\nWSRJ6jgzZ8INN8D//I9FpDpPmaltSZLUS11dsPrqcNhhVSeR+p6FpCRJTfKXvxQtfw4+GN761qrT\nSH2vVCEZEaMiYo/a34dFhLvdSJLUwJQp8PLLLrJR5yqzs80RwE+A02unRgI/b2YoSZLa3ZIlRcuf\n3XaDbbetOo3UHGVGJI8BdgFeAMjMB4ENmxlKkqR2d9ll8PDDjkaqs5UpJBdm5qJlBxExhFpzckmS\ntGJdXbDpprDPPlUnkZqnTCF5Y0R8DRgWEXsClwCXNTeWJEnt65574Ne/hrFjbfmjzlamkDweeAqY\nCXwRuAL4RjNDSZLUziZOLFr+HH541Umk5iq1s027c2cbSVJ/efZZGDkS9t+/WLUt9VRH7WwTETN5\n8zuRzwPTgW9l5jPNCCZJUjs680xYsMBFNhoYGo5IRsRJwBLgx7VT+wNrAH8CPpiZn2hqwj7giKQk\nqT8sWQLveEexyOamm6pOo3bVUSOSwB6ZuX3d8cyIuCMzt4+Ig5sVTJKkdnP55fDQQ3DyyVUnkfpH\nmcU2gyNix2UHEfF+YHDtcHFTUkmS1IYmTCjej9x336qTSP2jzIjk4cCZETECCIrG5IdHxHDgv5oZ\nTpKkdjF7Nlx3HXznO7b80cBRetV2RKwNkJnPNzVRE/iOpCSp2Y4+Gs46C+bNg/XXrzqN2lmnvSNJ\nRPwD8NfA6hEBQGae0MRckiS1jeeeg3PPhQMPtIjUwNLwHcmIOA34LDCOYmr708CoJueSJKltnHWW\nLX80MJVp/zMjM7et+3MEcGVm7to/EVedU9uSpGZZsgTe+U7YeGO4+eaq06gTtNPUdplV26/U/lwQ\nERsDrwJvK/PwCPaK4P4I5kRw/Aq+Py6C2RHMiOC6iDeOdEawVgTzIphYd26HCGbWnjkhgiiTRZKk\nZrjySpg719FIDUxlCsnLImId4GTgDuAhXm9O3q0IBgOTgL2BbYADIthmucvuBEZnsi3wE+Ck5b4/\nEVi+peupwBHAVrXPXiX+DZIkNcWECbDJJvCP/1h1Eqn/rbSQjIhBwHWZ+VxmXkrxbuS7MvPfSzx7\nR2BOJnMzWQRcCOxTf0Em12eyoHZ4GzDy9d9mB2Aj4Jq6c28D1srktkwSOBewW5ckqRL33gu/+lWx\nYvstb6k6jdT/VlpIZuZSilHFZccLe9D+ZxPg0brjebVz3TkMuBIggkHAd4F/XsEz5/XgmZIkNc3E\nibDaanDkkVUnkapRZmr7uoj4VCzr+9MEERwMjKaYPgcYC1yR+YaisafPPDKC6RFMX+z+O5KkPvb8\n83DOObD//rDBBlWnkapRpo/kF4HjgCUR8TJFC6DMzLUa3PcYsGnd8cjauTeIYA/g68BumSysnd4Z\n2DWCscAIYGgELwE/oG76u7tnAmQyGZgMMHw45bquS5JU0llnwfz5LrLRwFZ6Z5sePzgYAjwAfJSi\n2JsGHJjJrLprtqNYZLNXJg9285xDKRbkHFs7/j0wHvgdcAXQlckVK8ti+x9JUl9aurRo+bPRRnDL\nLVWnUafpqPY/UTg4Iv6tdrxpROzY6L5MFgPHAlcD9wIXZzIrghMiGFO77GSKEcdLIrgrgqklMo8F\nzgDmAH+g9l6lJEn95cor4Q9/gPHjq04iVatMQ/JTgaXARzLz3RGxLnBNZr6/PwL2BUckJUl9aa+9\nYOZMeOghV2ur73XUiCTwgcw8hlpj8sx8Fhja1FSSJLWo+++Hq6+25Y8E5QrJVyNiMBQLViJiA4oR\nSkmSBpyJE2HoUFv+SFCukJwA/AzYMCK+DfwG+E5TU0mS1IJeeAHOPrto+bPhhlWnkarXsP1PZp4f\nEbdTrL4OYN/MvLfpySRJajFnnw0vvWTLH2mZMottJgAXZuat/ROp77nYRpK0qpYuha23LpqP39q2\n/x9R7aDTFtvcDnwjIv4QEf8bEaObHUqSpFZz9dUwZ46jkVK90g3JI2I94FPA/sBmmblVM4P1JUck\nJUmrau+94e67i5Y/Q+1doibqtBHJZd4BvAsYBdzXnDiSJLWeBx6Aq66Co46yiJTqldnZ5qSIeBA4\nAbgHGJ2Zn2h6MkmSWsTEiUXPyC9+seokUmtpuGqbYhvCnTPz6WaHkSSp1Sxr+fPZzxZ7a0t6XZn2\nP6dHxLq1/bVXrzt/U1OTSZLUAs45B1580X21pRUp0/7ncOBLwEjgLmAn4LeZ+ZHmx+sbLraRJPXG\n0qXw7nfDuuvCbbdVnUYDRacttvkS8H7g4czcHdgOeK6pqSRJagHXXFMstHE0UlqxMoXkK5n5CkBE\nrJaZ9wFbNzeWJEnV6+qCv/or2G+/qpNIranMYpt5EbEO8HPgVxHxLPBwc2NJklStBx+EK66Ab37T\nlj9Sd8ostvnH2l+/GRHXA2sDVzU1lSRJFZs0yZY/UiNlRiRfk5k3NiuIJEmt4sUX4cwz4TOfKaa2\nJa1YT3a2kSRpQDj33KKYdF9taeVK77Xdzmz/I0kqa+lS2GYbWHtt+N3vqk6jgaid2v/0aGpbkqRO\nd+21cP/98KMfVZ1Ean2OSEqSVOfjH4fp0+Hhh2G11apOo4GonUYkfUdSkqSaOXOKlj9f/KJFpFSG\nhaQkSTWTJsHgwXDUUVUnkdqDhaQkScBLLxUtfz79aXjb26pOI7UHC0lJkiha/rzwgvtqSz3hYhtJ\n0oCXWbT8GTECfv97iKg6kQaydlpsY/sfSdKAd+21cN99xaikRaRUnlPbkqQBr6sLNtyw2BJRUnkW\nkpKkAW3uXPjlL235I/WGhaQkaUCz5Y/UexaSkqQB66WXYMoU2G8/2HjjqtNI7cdCUpI0YJ13Hjz/\nPIwbV3USqQci9iLifiLmEHH8Cr4/jojZRMwg4joiRjUtiu1/JEkDUSa85z0wbBhMm+ZqbbWOlbb/\niRgMPADsCcwDpgEHkDm77prdgd+RuYCIo4EPk/nZZmR1RFKSNCD9+tcwe3YxGmkRqTayIzCHzLlk\nLgIuBPZ5wxWZ15O5oHZ0GzCyWWEsJCVJA9KECbDBBvDZpozTSE2zCfBo3fG82rnuHAZc2awwNiSX\nJA04f/wjXHYZfO1rsPrqVaeR3mh9GELE9LpTk8mc3OMHRRwMjAZ266tsy7OQlCQNOJMmwaBBcPTR\nVSeR3uxpWEzm6G6+fgzYtO54ZO3cG0XsAXwd2I3MhX0essapbUnSgDJ/ftHy51Ofgk1WNiEotaZp\nwFZEbEHEUGB/YOobrojYDjgdGEPmk80MYyEpSRpQzjsPnnsOxo+vOonUC5mLgWOBq4F7gYv5/9u7\n9zC56vKA49+XLIFAuIYoFJINfQKtKBhiCLGNlVqoKU9NqtLmghcEitxC66U+2KvC46MtaisRgQiK\nbSMgQWjUWnqjXAqEBIgJCcKDlEtMuCOCuYe3f5yzzuxmN5lddnZmdr6f55ln55z3nJl3fvntzpvf\nOed3MlcTcRERM8utLgFGAzcQsYKIJX282uvm9D+SpLaRCUcfDSNHwn33ebW2mtNOp/9pMp4jKUlq\nG7feCqtXwze/aREpDQYPbUuS2saCBXDQQTBnTqMzkYYHC0lJUlt4/HFYsgT++I+d8kcaLBaSkqS2\n8LWvFYeznfJHGjwWkpKkYW/DBrjqKnjve2HcuF1vL6k2dS0kI5gRwcMRPBrBhb3EPx7BmghWRvBf\nEXSW6zsjuD+CFRGsjuDsqn3mRrCq3OffIjionp9BktT6Fi2Cl15yyh9psNVt+p8IRgCPACdR3Ady\nGTA3kzVV2/w2sDSTDRGcA5yQyewIRha5sTmC0cCDwG8AzwLrgKMyeT6CvwM2ZPKZneXi9D+S1L4y\n4ZhjYMQIeOABr9ZW82ul6X/qOSI5FXg0k8cy2QJcB8yq3iCTWzPZUC7eQ3GbHzLZkknX7Xz2qMoz\nysfeEQSwL0VhKUlSr267DR58sBiNtIiUBlc9C8lDgaeqlteW6/pyBvDDroUIxkWwsnyNv81kXSZb\ngXOAVZQjk8DVg524JGn4uPRSGDMG5s5tdCbS8NMUF9tE8AFgCsUtfQDI5KlMjgEmAh+O4I0R7E5R\nSB4L/AqwEvh0H695VgTLI1i+bVvdP4IkqQk98QT8y78UU/6MGtXobKThp56F5E+B6mvjDivXdRPB\nicBfADOrDmf/UibrKM6RfAcwqVz3k0wS+A7FuZM7yGRhJlMymdLh/XskqS197WvFT6f8keqjnoXk\nMuCICA4vL56ZA3S7aXgExwJXUhSRz1atPyyCUeXzA4DpwMMUhehREYwtNz2J4oblkiR1Uz3lz/jx\njc5GGp7qNlaXybYIzgduAUYA38hkdQQXAcszWUJxKHs0cEN5AvSTmcwE3gR8KYKkuLjmi5msAojg\ns8DtEWwFngBOq9dnkCS1rm9/G158EebPb3Qm0vBVt+l/monT/0hSe8mESZOK5ytWeLW2WksrTf/j\n2YOSpGHn9tth5Ur4+tctIqV6aoqrtiVJGkwLFsCBB8K8eY3ORBreLCQlScPKk0/CTTfBmWfCXns1\nOhtpeLOQlCQNK5dfXvw899zG5iG1AwtJSdKwsXEjLFwIs2ZBZ2ejs5GGPwtJSdKwce21xZQ/F1zQ\n6Eyk9uD0P5KkYSETJk+GbduKK7a9Wlutyul/JEkaYnfeWcwZuXChRaQ0VDy0LUkaFhYsgAMOgFNP\nbXQmUvuwkJQktbynnoLvftcpf6ShZiEpSWp5V1xRnCPplD/S0LKQlCS1tE2bivMiZ86ECRManY3U\nXiwkJUkt7brr4PnnYf78RmcitR+n/5EktaxMeNvbYMsWWLXKq7U1PDj9jyRJQ+Cuu+CBB4pzJC0i\npaHnoW1JUsu69FLYf3/4wAcanYnUniwkJUktae1auPFGOOMM2LslDgJKw4+FpCSpJV1xBbz2Gpx3\nXqMzkdqXhaQkqeV0TfnznvfA4Yc3OhupfVlISpJazvXXw3PPwQUXNDoTqb05/Y8kqaVkwnHHwcaN\n8OCDXq2t4cfpfyRJqpO774b77oPLL7eIlBrNQ9uSpJayYAHst59T/kjNwEJSktQy1q2DxYuLKX9G\nj250NpIsJCVJLeOKK2D7dqf8kZqFF9tIklrC5s0wfjwcfzwsWdLobKT6aaWLbRyRlCS1hO98B559\nFubPb3Qmkro4IilJanqZMHUq/OIXsHq1V2treGulEUmn/5EkNb2lS2H5crjsMotIqZl4aFuS1PQu\nvRT23Rc+9KFGZyKpmoWkJKmprVsHN9wAp5/ulD9Ss7GQlCQ1tSuvdMofqVl5sY0kqWlt3gydnTBl\nCnz/+43ORhoarXSxjSOSkqSmdcMN8MwzcMEFjc5EUm8ckZQkNa3jj4eXX4Y1a2A3hz7UJlppRNLp\nfyRJTWnpUrj3XvjqVy0ipWblr6YkqSktWAD77OOUP1Izs5CUJDWdp58ubol4+ulFMSmpOVlISpKa\nzpVXwtatTvkjNTsvtpEkNZUtW4opfyZPhh/8oNHZSEOvlS62cURSktRUFi8uDm3Pn9/oTCTtiiOS\nkv+UOQwAAA4rSURBVKSmMm0avPQSPPSQV2urPTkiKUnSANx7bzHtz/nnW0RKrcBfU0lS0+ia8ufD\nH250JpJqYSEpSWoKTz8N118Pp50G++7b6Gwk1aKuhWQEMyJ4OIJHI7iwl/jHI1gTwcoI/iuCznJ9\nZwT3R7AigtURnF21z8gIFkbwSAQ/juD99fwMu7JoEUyYUByCmTChWJaaiX1Uza6rjx5ySDHlT2dn\nozOSVKu6XWwTwQjgEeAkYC2wDJibyZqqbX4bWJrJhgjOAU7IZHYEI4vc2BzBaOBB4DcyWRfBZ4ER\nmfxlBLsBB2by/M5yqdfFNosWwVlnwYYNlXV77QULF8Kppw7620n9Zh9Vs7OPSjtqpYtt6llIvh34\nTCbvLpc/DZDJ5/vY/ljgq5n8Zo/1Y4AHgGllIfkU8OuZ1FwZ1quQnDABnnhix/V77gnvfOegv53U\nb7fdBps27bjePqpm0Vcf7eyExx8f8nSkptBKhWRHHV/7UOCpquW1wPE72f4M4IddCxGMA34ATAT+\nrCwi9y/DF0dwAvAT4PxMnhnMxGv15JO9r9+0CX72s6HNRepNb1/QXevto2oGffXRvv6+Smou9Swk\naxbBB4ApwC/HSDJ5Cjgmgl8Bbo5gMbAdOAy4K5OPR/Bx4IvAB3t5zbOAswBGjqxP3uPH9z4i2dkJ\n99xTn/eU+qOvUXP7qJpFX310/PghT0XSANTzYpufAuOqlg8r13UTwYnAXwAzM9ncM57JOopzJN8B\nvABsAL5bhm8AJvf25pkszGRKJlM66lQuf+5zxbk81fbaq1gvNQP7qJqdfVRqbfUsJJcBR0RweHnx\nzBxgSfUG5XmRV1IUkc9WrT8sglHl8wOA6cDDmSTwPeCEctPfgcrFO0Pt1FOLE8I7OyGi+OkJ4mom\n9lE1O/uo1NrqeovECE4G/gEYAXwjk89FcBGwPJMlEfwncDSwvtzlyUxmRnAS8CUggaC4CGdh+Zqd\nwD8B+wPPAR/JZKdn03iLREmS1Cpa6WIb77UtSZLURFqpkPTONpIkSRoQC0lJkiQNiIWkJEmSBsRC\nUpIkSQNiISlJkqQBsZCUJEnSgFhISpIk7cr69fDOd8LTTzc6k6ZiISlJkrQrF18Md95Z/NQvOSG5\nJElqHtu3QyZ0dBTLL7wAW7fCtm2Vx957wyGHFPHly2HLlu7xN74R3vrWIr54MWzeXKzvep2JE+HE\nE4v4JZfApk3d45Mmwbx5Rfzcc4scbryxyG3UKHjsMTj44Lo1QStNSG4hORjWr4c5c+D66+vasaQB\ns4+q2dlH+9azSNq6FUaOhAMOKOKPPLLjNgceCEceWcRvuaVSSHU9xo+H6dOL+JVXVgqprtc/6ih4\n3/uK+Kc/DRs2dI9PnQpnn13E586FV1/t/vrvehf81V8V8WnTuse3boWZM2HBgiJ+8MHw859X4pnF\nzdb/+Z+L+F57wcaN3dtkV/F582DRouL53nsX+dcS7+goHvPmwdVXF+smToRnnik+AxRtf+aZcNll\ntf37DUArFZIdjU5gWKge7q5jx5IGzD6qZldLH82sFBsRsOeexfr167uPWG3dCvvsUxRLAHff3b2Q\n2rq1KF6OO66IX3ttUYhUF0ITJ8LJJxfxz39+x0Jq0iQ47bQi/tGP7lgoTZ8On/pUEX/3u7sXStu2\nFeu++MUi/mu/Bi+/3H3/U06Bb32riI8ZUyliusydC9/+dvF88mToOVhSHT/llB33nzOnUkh+8pM7\nxmfPrhSS11xTFJpdRVZHB4weXdn28ceL9u3ogN13r4wkdpkwofhc1fu/5S2V+Ec+Uoz0VcePOaYS\n//KXKyOUXa9/+OGV+E03FT+r4294QyV+330wYkT319+7qkZ74YViv912K/pVT3fcAb/6q5XlLVvg\nm98sCuVG/acnYgbwFWAEcBWZX+gR3wP4R+BtwAvAbDIfr0sqjki+TuvXFx1s06aiA44bV/klOvnk\nyv+4Jk2CV17pvq9x40MRX78eDj20+ENc3UebJT/jxt/8ZnjooaKPAowdC7Nmwde/Xiy/4Q3Fl/1r\nr1X2nz0brruueL7ffkWhVm1X8T/6o2L0s9b4K69UipSOjqI46xqxOvroohCtjs+YURSgAO95z46F\n1vTp8LGPFfH584visTo+aVIx6gbwpS/tWGgdeWTl0OyNN1YKra7HoYcWeUFx6Dei++vvu2+lCHru\nue77dj16K6ra0bnnFv/WW7ZU1tV5VHKnI5IRI4BHgJOAtcAyYC6Za6q2ORc4hsyziZgDvJfM2fXI\n1RHJ1+viiyt/3Lr+hzx1arHcdVgB4PjjdxxaN258KOIXX1z0za5CsquPNkt+xo139c3MYlRo7NjK\n31GA887bsdB605sq8a98pSi0qgu5zs5K/Oabi5/V8TFjKvEVK4r3rX79PfaoxF96qYj3ZdWqvmMA\n3/vezuNdBXVfPvGJncff//6dx6dM2Xl87Nidx9vd3Xd3LyKhWL7rrsbkA1OBR8l8DICI64BZwJqq\nbWYBnymfLwa+SkRQh9FDRyRfj+rRyC5DcBKuVDP7qJqdfVTawS5GJE8BZpB5Zrn8QeB4Ms+v2ubB\ncpu15fJPym2eH+xc22JEcsOGDRkRG3e9Zf+Mh5EHQUf14H9u3Mjzhxyy7UnY0ueOqlUHsK3RSbQy\n+2jd2UdfJ/to3dlHB9eQtOceMIqI5VWrFpK5sN7vOxBtUUhmZt3ny4yI5Zm5i+MH6g/bdHDZnoPP\nNh1ctufgs00HV5O050+BcVXLh5XrettmLREdwH4UF90MOicklyRJah3LgCOIOJyIkcAcYEmPbZYA\nHy6fnwL8dz3Oj4Q2GZGUJEkaFjK3EXE+cAvF9D/fIHM1ERcBy8lcAlwN/BMRjwIvUhSbdWEhOXia\n8tyFFmebDi7bc/DZpoPL9hx8tungao72zPxX4F97rPvrquebgD8cilTa4qptSZIkDT7PkZQkSdKA\nWEj2U0TMiIiHI+LRiLiwl/geEXF9GV8aEROGPsvWUUN7nhYRz0XEivJxZiPybBUR8Y2IeDaKOcR6\ni0dEXFq298qImDzUObaaGtr0hIh4uaqP/nVv26kQEeMi4taIWBMRqyPiT3rZxn7aDzW2qf20RhGx\nZ0TcGxE/Ktvzs71s43d9yUKyH6K4LdFlwO8BRwFzI+KoHpudAbyUmROBvwf+dmizbB01tifA9Zk5\nqXxcNaRJtp5rgBk7if8ecET5OAu4fAhyanXXsPM2Bbijqo9eNAQ5tbJtwCcy8yhgGnBeL7/39tP+\nqaVNwX5aq83AuzLzrcAkYEZETOuxjd/1JQvJ/pkKPJqZj2XmFqDrtkTVZgHfKp8vBn4nwhuW9qGW\n9lQ/ZObtFFfo9WUW8I9ZuAfYPyIOGZrsWlMNbap+yMz1mXl/+fwV4CHg0B6b2U/7ocY2VY3Kfvdq\nubh7+eh5QYnf9SULyf45FHiqanktO/6y/nKbzNwGvAyMQb2ppT0B3l8e3locEeN6iat2tba5+uft\n5WGwH0bEmxudTKsoDwceCyztEbKfDtBO2hTspzWLiBERsQJ4FviPzOyzj7b7d72FpJrd94AJmXkM\n8B9U/gcoNYv7gc7yMNgC4OYG59MSImI0cCPwp5n580bnMxzsok3tp/2QmdszcxLFXWOmRsRbGp1T\ns7KQ7J/+3JaIqPNtiYaBXbZnZr6QmZvLxauAtw1RbsNVLX1Y/ZCZP+86DJbF3G67R8RBDU6rqUXE\n7hQFz6LM/G4vm9hP+2lXbWo/HZjM/BlwKzueJ+13fclCsn+WAUdExOHRj9sSpZN19mWX7dnjvKiZ\nFOf+aOCWAB8qr4qdBrycmesbnVQri4iDu86NioipFH9X2/ILpRZlW10NPJSZX+5jM/tpP9TSpvbT\n2kXE2IjYv3w+CjgJ+HGPzfyuL3lnm37IzG3R47ZEmbk6ytsSZdVtiWIIbkvU6mpszwsiYibFVYkv\nAqc1LOEWEBHXAicAB0XEWuBvKE4UJzOvoLgTwsnAo8AG4CONybR11NCmpwDnRMQ2YCMwp12/UGr0\nm8AHgVXlOWgAfw6MB/vpANXSpvbT2h0CfKucWWQ34DuZ+X2/63vnnW0kSZI0IB7aliRJ0oBYSEqS\nJGlALCQlSZI0IBaSkiRJGhALSUmSJA2IhaSkthERd5U/J0TEvEF+7T/v7b0kaThz+h9JbSciTgA+\nmZm/3499Osp76vYVfzUzRw9GfpLUKhyRlNQ2IuLV8ukXgHdExIqI+FhEjIiISyJiWUSsjIiPltuf\nEBF3RMQSYE257uaIuC8iVkfEWeW6LwCjytdbVP1e5d1ZLomIByNiVUTMrnrt/4mIxRHx44hY1HXn\nEUlqFd7ZRlI7upCqEcmyIHw5M4+LiD2A/42Ify+3nQy8JTP/r1w+PTNfLG+dtiwibszMCyPi/Myc\n1Mt7vQ+YBLwVOKjc5/YydizwZmAd8L8Udyi5c/A/riTVhyOSkgS/S3Fv5xXAUmAMcEQZu7eqiITi\ntp0/Au4BxlVt15fpwLWZuT0znwFuA46reu21mfkasAKYMCifRpKGiCOSkgQBzM/MW7qtLM6l/EWP\n5ROBt2fmhoj4H2DP1/G+m6ueb8e/yZJajCOSktrRK8A+Vcu3AOdExO4AEXFkROzdy377AS+VReSv\nA9OqYlu79u/hDmB2eR7mWOC3gHsH5VNIUoP5v19J7WglsL08RH0N8BWKw8r3lxe8PAf8QS/7/Rtw\ndkQ8BDxMcXi7y0JgZUTcn5mnVq2/CXg78CMggU9l5tNlISpJLc3pfyRJkjQgHtqWJEnSgFhISpIk\naUAsJCVJkjQgFpKSJEkaEAtJSZIkDYiFpCRJkgbEQlKSJEkDYiEpSZKkAfl/JJgoN5JdIhwAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb47b919860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHVCAYAAAAzabX0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb487325a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax1 = plt.subplots()\n",
    "t = len(plot_avg_rew)\n",
    "plt.plot(range(t),plot_avg_rew,'b-o')\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('average episode reward, per agent per step')\n",
    "ax1.tick_params('y', colors='b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "plt.plot(range(t),plot_frac_burn,'r--^')\n",
    "ax2.set_ylabel('fraction of healthy trees')\n",
    "ax2.tick_params('y', colors='r')\n",
    "ax2.set_ylim([0,1])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(len(plot_loss_hist)), plot_loss_hist, 'k--s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the performance of the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def heuristic_trajectory(pos, center, num_actions, img_st, hasfire, control):\n",
    "#     trajectory = []\n",
    "#     actions = []\n",
    "#     trajectory.append((pos[0],pos[1]))\n",
    "#     img_dim = img_st.shape[0]\n",
    "    \n",
    "#     if hasfire:\n",
    "#         fires_r, fires_c = np.where(img_st==1)\n",
    "#         neighbors = [(-1,0),(1,0),(0,1),(0,-1)]\n",
    "#         fire = []\n",
    "#         bdry = []\n",
    "#         for r,c in zip(fires_r,fires_c):\n",
    "#             counter = 0\n",
    "#             for (dr,dc) in neighbors:\n",
    "#                 rn = r + dr\n",
    "#                 cn = c + dc\n",
    "#                 if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] == 0:\n",
    "#                     counter += 1\n",
    "                    \n",
    "#             x = col_to_x(c) - img_dim//2 + pos[0]\n",
    "#             y = row_to_y(img_dim,r) - img_dim//2 + pos[1]\n",
    "#             if counter >= 2 and (x,y) not in control:\n",
    "#                 bdry.append((x,y))\n",
    "#             elif (x,y) not in control:\n",
    "#                 fire.append((x,y))\n",
    "                \n",
    "#         target = None\n",
    "#         using_bdry = False\n",
    "#         if len(bdry) > 0:\n",
    "#             dists = [(np.abs(x-pos[0])+np.abs(y-pos[1]),(x,y)) for (x,y) in bdry]\n",
    "#             using_bdry = True\n",
    "#             target = min(dists)[1]\n",
    "#         #elif len(fire) > 0:\n",
    "#         #    dists = [(np.abs(x-pos[0])+np.abs(y-pos[1]),(x,y)) for (x,y) in fire]\n",
    "#         #    target = min(dists)[1]\n",
    "#         else:\n",
    "#             target = trajectory[-1]\n",
    "    \n",
    "#         while len(trajectory) < num_actions+1:\n",
    "#             loc = trajectory[-1]\n",
    "#             if loc == target:\n",
    "#                 if using_bdry:\n",
    "#                     bdry.remove(target)\n",
    "#                 #elif len(fire) > 0:\n",
    "#                 #    fire.remove(target)\n",
    "                    \n",
    "#                 target = None\n",
    "#                 using_bdry = False\n",
    "#                 if len(bdry) > 0:\n",
    "#                     dists = [(np.abs(x-loc[0])+np.abs(y-loc[1]),(x,y)) for (x,y) in bdry]\n",
    "#                     target = min(dists)[1]\n",
    "#                     using_bdry = True\n",
    "#                 #elif len(fire) > 0:\n",
    "#                 #    dists = [(np.abs(x-loc[0])+np.abs(y-loc[1]),(x,y)) for (x,y) in fire]\n",
    "#                 #    target = min(dists)[1]\n",
    "#                 else:\n",
    "#                     target = trajectory[-1]\n",
    "                    \n",
    "#             dists = []\n",
    "#             for a in range(9):\n",
    "#                 new_loc = actions_to_trajectory(trajectory[-1],[a])[1]\n",
    "#                 dists.append((np.abs(new_loc[0]-target[0])+np.abs(new_loc[1]-target[1]),new_loc,a))\n",
    "                \n",
    "#             trajectory.append(min(dists)[1])\n",
    "#             actions.append(min(dists)[2])\n",
    "#             #print(trajectory)\n",
    "        \n",
    "#     else:\n",
    "#         for k in range(num_actions):\n",
    "#             dists = []\n",
    "#             for a in range(9):\n",
    "#                 new_loc = actions_to_trajectory(trajectory[-1],[a])[1]\n",
    "#                 dists.append((np.abs(center-new_loc[0])+np.abs(center-new_loc[1]),new_loc,a))\n",
    "            \n",
    "#             trajectory.append(min(dists)[1])\n",
    "#             actions.append(min(dists)[2])\n",
    "            \n",
    "#     return trajectory, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def heuristic_trajectory(pos, img_st, center, close_pos, num_actions, grid_size, last_step, curr_agent):\n",
    "#     #print('---')\n",
    "#     #print(img_st)\n",
    "#     traj = []\n",
    "#     actions = []\n",
    "#     traj.append((pos[0],pos[1]))\n",
    "#     img_dim = img_st.shape[0]\n",
    "#     fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "#     move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "    \n",
    "#     for k in range(num_actions):\n",
    "#         dists = None\n",
    "#         x,y = traj[k]\n",
    "        \n",
    "#         near_fire = False\n",
    "#         #r = y_to_row(grid_size,y)\n",
    "#         #c = x_to_col(x)  \n",
    "#         r = img_dim//2\n",
    "#         c = img_dim//2\n",
    "#         for (dr,dc) in move_neigh:\n",
    "#             rn = r + dr\n",
    "#             cn = c + dc\n",
    "#             if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] in [1,2]:\n",
    "#                 near_fire = True\n",
    "#                 break \n",
    "        \n",
    "#         if near_fire:\n",
    "#             cen_vec = np.array([x-center,y-center])\n",
    "#             cen_vec = cen_vec/np.linalg.norm(cen_vec)\n",
    "#             perp_vec = np.array([cen_vec[1],-cen_vec[0]])/np.linalg.norm(cen_vec)\n",
    "#             #print(vec)\n",
    "#             #print(perp_vec)\n",
    "\n",
    "#             dists = []\n",
    "#             for a in range(1,9):\n",
    "#                 new_loc = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 r = -new_loc[1] + y + img_dim//2\n",
    "#                 c = new_loc[0] - x + img_dim//2\n",
    "                \n",
    "#                 incntv = 0\n",
    "#                 #if False and last_step and img_st[r,c]==0:\n",
    "#                 #    #print(a,' ',last_step,' ',img_st[r,c])\n",
    "#                 #    incntv += -2\n",
    "#                 #    \n",
    "#                 #elif False and not last_step and img_st[r,c]==1:\n",
    "#                 #    counter = 0\n",
    "#                 #    for (dr,dc) in fire_neigh:\n",
    "#                 #        rn = r + dr\n",
    "#                 #        cn = c + dc\n",
    "#                 #        if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn]==0:\n",
    "#                 #            counter += 1\n",
    "#                 #            \n",
    "#                 #    if counter>=2:\n",
    "#                 #        incntv += -5\n",
    "#                 #    elif counter>=1:\n",
    "#                 #        incntv += -3\n",
    "#                 #        \n",
    "#                 #elif False and not last_step and img_st[r,c]==0:\n",
    "#                 #    incntv += -1\n",
    "#                 #        \n",
    "#                 #if np.linalg.norm(new_loc-close_pos,1)<=1:\n",
    "#                 #    incntv += 2\n",
    "                \n",
    "#                 if img_st[r,c] in [1,2]:\n",
    "#                     counter = 0\n",
    "#                     for (dr,dc) in fire_neigh:\n",
    "#                         rn = r + dr\n",
    "#                         cn = c + dc\n",
    "#                         if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn]==0:\n",
    "#                             counter += 1\n",
    "                            \n",
    "                            \n",
    "#                     if img_st[r,c] == 1:\n",
    "#                         incntv += counter*-0.5\n",
    "#                     else:\n",
    "#                         incntv += counter*-0.25\n",
    "                   \n",
    "#                     #if counter==1 and img_st[r,c]==1:\n",
    "#                     #    incntv += -1.25\n",
    "#                     #elif counter>=2 and img_st[r,c]==1:\n",
    "#                     #    incntv += -1.75\n",
    "#                     #elif counter>=2 and img_st[r,c]==2:\n",
    "#                     #    incntv += -1\n",
    "#                     #else:\n",
    "#                     #   incntv += -0.5\n",
    "\n",
    "#                 move_vec = np.array([new_loc[0]-x,new_loc[1]-y])\n",
    "#                 if a != 0:\n",
    "#                     move_vec = move_vec/np.linalg.norm(move_vec)\n",
    "#                 #print(a,' ',incntv)\n",
    "                \n",
    "#                 #dists.append((np.linalg.norm(perp_vec-move_vec)+incntv,new_loc,a))\n",
    "#                 dists.append((np.cross(cen_vec,move_vec)+incntv,new_loc,a))\n",
    "                \n",
    "#                 #if curr_agent == 4:\n",
    "#                 #    print(dists)\n",
    "\n",
    "#             #print(img_st)\n",
    "#             #print(dists)\n",
    "#             #5/0\n",
    "                \n",
    "#             #traj.append(min(dists)[1])\n",
    "#             #actions.append(min(dists)[2])\n",
    "#             #pot_pos = min(dists)[1]\n",
    "            \n",
    "            \n",
    "#         else:\n",
    "            \n",
    "#             #if agent_dist <= -1:\n",
    "#             #    traj.append(traj[-1])\n",
    "#             #    actions.append(0)\n",
    "#             #\n",
    "#             #else:\n",
    "#                 #print('moving to center')\n",
    "#             dists = []\n",
    "#             for a in range(9):\n",
    "#                 new_loc = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 incntv = 0\n",
    "#                 #if np.linalg.norm(new_loc-close_pos,1)<=1:\n",
    "#                 #    incntv += 2\n",
    "#                 dists.append((np.abs(center-new_loc[0])+np.abs(center-new_loc[1])+incntv,new_loc,a))\n",
    "\n",
    "#             #traj.append(min(dists)[1])\n",
    "#             #actions.append(min(dists)[2])\n",
    "            \n",
    "#         #pot_pos = min(dists)[1]\n",
    "#         #pot_act = min(dists)[2]\n",
    "        \n",
    "#         #if np.linalg.norm(pot_pos-close_pos,1)<=1: # or np.linalg.norm(traj[k]-close_pos,1)<=0.5:\n",
    "#         #    #print('agent should stop')\n",
    "#         #    traj.append(traj[-1])\n",
    "#         #    actions.append(0)\n",
    "#         #else:\n",
    "#         #    traj.append(pot_pos)\n",
    "#         #    actions.append(pot_act)\n",
    "        \n",
    "#         traj.append(min(dists)[1])\n",
    "#         actions.append(min(dists)[2])\n",
    "    \n",
    "#     #print('---')\n",
    "#     #print()\n",
    "    \n",
    "#     return traj, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def heuristic_trajectory(pos, img_st, center, close_pos, num_actions, grid_size, last_step, curr_agent):\n",
    "\n",
    "#     traj = []\n",
    "#     actions = []\n",
    "#     traj.append((pos[0],pos[1]))\n",
    "#     img_dim = img_st.shape[0]\n",
    "#     fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "#     move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "#     action_set = [4,1,2,3,5,8,7,6]\n",
    "    \n",
    "#     for k in range(num_actions):\n",
    "#         dists = None\n",
    "#         x,y = traj[k]\n",
    "\n",
    "#         r = img_dim//2\n",
    "#         c = img_dim//2\n",
    "        \n",
    "#         if img_st[r,c] in [1,2]:\n",
    "#             dists = []\n",
    "#             cen_vec = np.array([x-center,y-center])\n",
    "#             cen_vec = cen_vec/np.linalg.norm(cen_vec)\n",
    "#             perp_vec = np.array([cen_vec[1],-cen_vec[0]])/np.linalg.norm(cen_vec)\n",
    "            \n",
    "#             #for a in range(1,9):\n",
    "#             for idx,a in enumerate(action_set):\n",
    "#                 new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 rl = -new_pos[1] + y + img_dim//2\n",
    "#                 cl = new_pos[0] -x + img_dim//2\n",
    "                \n",
    "#                 if img_st[rl,cl] == 0:\n",
    "#                     continue\n",
    "                    \n",
    "#                 move_vec = np.array([new_pos[0]-x,new_pos[1]-y])\n",
    "#                 if a != 0:\n",
    "#                     move_vec = move_vec/np.linalg.norm(move_vec)\n",
    "                \n",
    "#                 score = 0\n",
    "                \n",
    "#                 if np.cross(cen_vec,move_vec)<0:\n",
    "#                     #print(a,' ',cen_vec,' ',move_vec,' ',np.cross(cen_vec,move_vec))\n",
    "#                     score += -0.5\n",
    "\n",
    "#                 #bdry = False\n",
    "#                 #for (dr,dc) in fire_neigh:\n",
    "#                 #    rn = rl + dr\n",
    "#                 #    cn = cl + dc\n",
    "#                 #    if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn]==0:\n",
    "#                 #        bdry = True\n",
    "#                 #        break\n",
    "#                 counter = 0\n",
    "#                 for (dr,dc) in fire_neigh:\n",
    "#                     rn = rl + dr\n",
    "#                     cn = cl + dc\n",
    "#                     if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn]==0:\n",
    "#                         counter += 1\n",
    "                \n",
    "#                 #if bdry:\n",
    "#                 #    score += -0.75\n",
    "#                 #else:\n",
    "#                 #    continue\n",
    "                \n",
    "#                 #if counter==0:\n",
    "#                 #    continue\n",
    "#                 if counter==1:\n",
    "#                     score += -0.75\n",
    "#                 elif counter>=2:\n",
    "#                     score += -0.85\n",
    "                    \n",
    "#                 score += -0.01*(len(action_set)-idx)\n",
    "#                 #print(a,' ',score)\n",
    "\n",
    "#                 dists.append((score,new_pos,a))\n",
    "                \n",
    "#             #print(dists)\n",
    "#             #print()\n",
    "            \n",
    "#         else:\n",
    "#             dists = []\n",
    "#             for a in range(9):\n",
    "#                 new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1]),new_pos,a))\n",
    "        \n",
    "#         traj.append(min(dists)[1])\n",
    "#         actions.append(min(dists)[2])\n",
    "        \n",
    "#     return traj, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def heuristic_trajectory(pos, img_st, center, close_pos, num_actions, grid_size, last_step, curr_agent):\n",
    "\n",
    "#     traj = []\n",
    "#     actions = []\n",
    "#     traj.append((pos[0],pos[1]))\n",
    "#     img_dim = img_st.shape[0]\n",
    "#     fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "#     move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "#     action_set = [4,1,2,3,5,8,7,6]\n",
    "    \n",
    "#     for k in range(num_actions):\n",
    "#         dists = None\n",
    "#         x,y = traj[k]\n",
    "\n",
    "#         r = img_dim//2\n",
    "#         c = img_dim//2\n",
    "        \n",
    "#         near_fire = False\n",
    "#         for (dr,dc) in move_neigh:\n",
    "#             rn = r + dr\n",
    "#             cn = c + dc\n",
    "#             if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] in [1,2]:\n",
    "#                 near_fire = True\n",
    "#                 break\n",
    "        \n",
    "#         if img_st[r,c] in [1,2] or near_fire:\n",
    "#             dists = []\n",
    "#             action_set = None\n",
    "#             ang = np.arctan2(y-center,x-center)\n",
    "#             if ang>=0 and ang<np.pi/4:\n",
    "#                 quad=1\n",
    "#                 action_set = [5,8,7,6]\n",
    "#             elif ang>=np.pi/4 and ang<np.pi/2:\n",
    "#                 quad=2\n",
    "#                 action_set = [3,5,8,7]\n",
    "#             elif ang>=np.pi/2 and ang<(3*np.pi)/4:\n",
    "#                 quad=3\n",
    "#                 action_set = [2,3,5,8]\n",
    "#             elif ang>=(3*np.pi)/4:\n",
    "#                 quad=4\n",
    "#                 action_set = [1,2,3,5]\n",
    "#             elif ang<=(-3*np.pi)/4:\n",
    "#                 quad=5\n",
    "#                 action_set = [4,1,2,3]\n",
    "#             elif ang>(-3*np.pi)/4 and ang<=(-np.pi/2):\n",
    "#                 quad=6\n",
    "#                 action_set = [6,4,1,2]\n",
    "#             elif ang>(-np.pi/2) and ang<=(-np.pi/4):\n",
    "#                 quad=7\n",
    "#                 action_set = [7,6,4,1]\n",
    "#             elif ang>(-np.pi/4) and ang<0:\n",
    "#                 quad=8\n",
    "#                 action_set = [8,7,6,4]\n",
    "\n",
    "#             '''\n",
    "#             if ang>=0 and ang<np.pi/2:\n",
    "#                 quad=1\n",
    "#                 #action_set = [2,3,5,8,7]\n",
    "#                 action_set = [3,5,8,7,6]\n",
    "#             elif ang>=np.pi/2:\n",
    "#                 quad=2\n",
    "#                 action_set = [1,2,3,5,8]\n",
    "#             elif ang<0 and ang>-np.pi/2:\n",
    "#                 quad=4\n",
    "#                 #action_set = [7,6,4,1,2,8]\n",
    "#                 action_set = [8,7,6,4,1]\n",
    "#             elif ang<=-np.pi/2:\n",
    "#                 quad=3\n",
    "#                 #action_set = [4,1,2,3,5,6]\n",
    "#                 action_set = [6,4,1,2,3]\n",
    "#             '''\n",
    "                \n",
    "#             for a in action_set:\n",
    "#                 new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 rl = -new_pos[1] + y + img_dim//2\n",
    "#                 cl = new_pos[0] -x + img_dim//2\n",
    "                \n",
    "#                 if img_st[rl,cl] == 0:\n",
    "#                     continue\n",
    "                    \n",
    "#                 counter = 0\n",
    "#                 for (dr,dc) in fire_neigh:\n",
    "#                     rn = rl + dr\n",
    "#                     cn = cl + dc\n",
    "#                     if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn]==0:\n",
    "#                         counter += 1\n",
    "                        \n",
    "#                 if counter>=1:\n",
    "#                     dists.append((0,new_pos,a))\n",
    "#                     break     \n",
    "        \n",
    "#             #print('quadrant = ',quad)\n",
    "#             #print()\n",
    "\n",
    "#         else:\n",
    "#             dists = []\n",
    "#             for a in range(9):\n",
    "#                 new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1]),new_pos,a))\n",
    "        \n",
    "#         #if not dists:\n",
    "#         #    print('current agent = ', curr_agent)\n",
    "#         #    print('agent position = ', pos)\n",
    "#         #    print('quadrant = ', quad)\n",
    "#         #    print('actions = ', action_set)\n",
    "        \n",
    "#         if not dists:\n",
    "#             dists = []\n",
    "#             cen_vec = np.array([x-center,y-center])\n",
    "#             cen_vec = cen_vec/np.linalg.norm(cen_vec)\n",
    "#             for a in range(1,9):\n",
    "#                 new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 move_vec = np.array([new_pos[0]-x,new_pos[1]-y])\n",
    "#                 if a != 0:\n",
    "#                     move_vec = move_vec/np.linalg.norm(move_vec)\n",
    "#                 dists.append((np.cross(cen_vec,move_vec),new_pos,a))\n",
    "          \n",
    "#         pot_act = min(dists)[2]\n",
    "#         new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#         if np.linalg.norm(new_pos-close_pos,1)<=1:\n",
    "#             traj.append(traj[-1])\n",
    "#             actions.append(0)\n",
    "#         else:        \n",
    "#             traj.append(min(dists)[1])\n",
    "#             actions.append(min(dists)[2])\n",
    "        \n",
    "#     return traj, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def heuristic_trajectory(pos, img_st, center, close_pos, num_actions, grid_size, last_step, curr_agent, seen_fire):\n",
    "\n",
    "#     traj = []\n",
    "#     actions = []\n",
    "#     traj.append((pos[0],pos[1]))\n",
    "#     img_dim = img_st.shape[0]\n",
    "#     fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "#     move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "#     action_set = [4,1,2,3,5,8,7,6]\n",
    "    \n",
    "#     for k in range(num_actions):\n",
    "#         dists = None\n",
    "#         x,y = traj[k]\n",
    "\n",
    "#         r = img_dim//2\n",
    "#         c = img_dim//2\n",
    "        \n",
    "#         #elif near_fire:\n",
    "#         if img_st[r,c] in [1,2] or seen_fire:\n",
    "#             seen_fire = True\n",
    "            \n",
    "#             #near_fire = False\n",
    "#             #for (dr,dc) in move_neigh:\n",
    "#             #    rn = r + dr\n",
    "#             #    cn = c + dc\n",
    "#             #    if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] in [1,2]:\n",
    "#             #        near_fire = True\n",
    "#             #        break\n",
    "                    \n",
    "#             counter = 0\n",
    "#             for (dr,dc) in move_neigh:\n",
    "#                 rn = r + dr\n",
    "#                 cn = c + dc\n",
    "#                 if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] in [1,2]:\n",
    "#                     counter += 1\n",
    "            \n",
    "            \n",
    "#             if last_step and counter>=7:\n",
    "#                 dists = []\n",
    "#                 for a in range(9):\n",
    "#                     new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                     dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1]),new_pos,a))\n",
    "\n",
    "#                 traj.append(max(dists)[1])\n",
    "#                 actions.append(max(dists)[2])\n",
    "                \n",
    "#             elif False and last_step and counter<=4:\n",
    "#                 dists = []\n",
    "#                 for a in range(9):\n",
    "#                     new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                     dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1]),new_pos,a))\n",
    "\n",
    "#                 traj.append(min(dists)[1])\n",
    "#                 actions.append(min(dists)[2])\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 dists = []\n",
    "#                 cen_vec = np.array([x-center,y-center])\n",
    "#                 cen_vec = cen_vec/np.linalg.norm(cen_vec)\n",
    "#                 for a in range(1,9):\n",
    "#                     new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                     move_vec = np.array([new_pos[0]-x,new_pos[1]-y])\n",
    "#                     if a != 0:\n",
    "#                         move_vec = move_vec/np.linalg.norm(move_vec)\n",
    "#                     dists.append((np.cross(cen_vec,move_vec),new_pos,a))\n",
    "\n",
    "#                 traj.append(min(dists)[1])\n",
    "#                 actions.append(min(dists)[2])      \n",
    "                \n",
    "#             '''\n",
    "\n",
    "            \n",
    "#             if counter<=3:\n",
    "#                 dists = []\n",
    "#                 for a in range(9):\n",
    "#                     new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                     dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1]),new_pos,a))\n",
    "\n",
    "#                 traj.append(min(dists)[1])\n",
    "#                 actions.append(min(dists)[2])\n",
    "                \n",
    "#             elif counter>=7:\n",
    "#                 dists = []\n",
    "#                 for a in range(9):\n",
    "#                     new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                     dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1]),new_pos,a))\n",
    "\n",
    "#                 traj.append(max(dists)[1])\n",
    "#                 actions.append(max(dists)[2])\n",
    "            \n",
    "#             else:\n",
    "#             '''\n",
    "\n",
    "\n",
    "#         else:\n",
    "#             dists = []\n",
    "#             for a in range(9):\n",
    "#                 new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1]),new_pos,a))\n",
    "                \n",
    "#             traj.append(min(dists)[1])\n",
    "#             actions.append(min(dists)[2])\n",
    "        \n",
    "#     return traj, actions, seen_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heuristic_trajectory(pos, img_st, center, close_pos, num_actions, grid_size, \n",
    "                         last_step, curr_agent, close_agent_id, seen_fire):\n",
    "\n",
    "    traj = []\n",
    "    actions = []\n",
    "    traj.append((pos[0],pos[1]))\n",
    "    img_dim = img_st.shape[0]\n",
    "    fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "    move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "    action_set = [4,1,2,3,5,8,7,6]\n",
    "    \n",
    "    for k in range(num_actions):\n",
    "        dists = None\n",
    "        x,y = traj[k]\n",
    "\n",
    "        r = img_dim//2\n",
    "        c = img_dim//2\n",
    "        \n",
    "        near_fire = False\n",
    "        for (dr,dc) in move_neigh:\n",
    "            rn = r + dr\n",
    "            cn = c + dc\n",
    "            if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] in [1,2]:\n",
    "                near_fire = True\n",
    "                break\n",
    "        \n",
    "        if img_st[r,c] in [1,2] or seen_fire:\n",
    "            seen_fire = True\n",
    "        \n",
    "            dists = []\n",
    "            cen_vec = np.array([x-center,y-center])\n",
    "            cen_vec = cen_vec/np.linalg.norm(cen_vec)\n",
    "            for a in range(1,9):\n",
    "            #for a in [2,5,7,4]:\n",
    "                new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                \n",
    "                rl = -new_pos[1] + y + img_dim//2\n",
    "                cl = new_pos[0] -x + img_dim//2\n",
    "                #if a in [1,3,8,6] and img_st[rl,cl] in [0]:\n",
    "                #    continue\n",
    "                \n",
    "                move_vec = np.array([new_pos[0]-x,new_pos[1]-y])\n",
    "                if a != 0:\n",
    "                    move_vec = move_vec/np.linalg.norm(move_vec)\n",
    "                dists.append((np.cross(cen_vec,move_vec),new_pos,a))\n",
    "            \n",
    "\n",
    "            cir_pos = min(dists)[1]\n",
    "            cir_act = min(dists)[2]\n",
    "                \n",
    "            ri = -cir_pos[1] + y + img_dim//2\n",
    "            ci = cir_pos[0] -x + img_dim//2\n",
    "            \n",
    "            left_act = None\n",
    "            if cir_act==1:\n",
    "                left_act = [6,4]\n",
    "                #left_act = [4]\n",
    "                righ_act = [2]\n",
    "            elif cir_act==2:\n",
    "                left_act = [4,1]\n",
    "                #left_act = [1]\n",
    "                righ_act = [3]\n",
    "            elif cir_act==3:\n",
    "                left_act = [1,2]\n",
    "                #left_act = [2]\n",
    "                righ_act = [5]\n",
    "            elif cir_act==5:\n",
    "                left_act = [2,3]\n",
    "                #left_act = [3]\n",
    "                righ_act = [8]\n",
    "            elif cir_act==8:\n",
    "                left_act = [3,5]\n",
    "                #left_act = [5]\n",
    "                righ_act = [7]\n",
    "            elif cir_act==7:\n",
    "                left_act = [5,8]\n",
    "                #left_act = [8]\n",
    "                righ_act = [6]\n",
    "            elif cir_act==6:\n",
    "                left_act = [8,7]\n",
    "                #left_act = [7]\n",
    "                righ_act = [4]\n",
    "            elif cir_act==4:\n",
    "                left_act = [7,6]\n",
    "                #left_act = [6]\n",
    "                righ_act = [1]\n",
    "            \n",
    "            '''\n",
    "            left_act = None\n",
    "            if cir_act==2:\n",
    "                #left_act = [3]\n",
    "                left_act = [1]\n",
    "            elif cir_act==5:\n",
    "                #left_act = [8]\n",
    "                left_act = [3]\n",
    "            elif cir_act==7:\n",
    "                #left_act = [6]\n",
    "                left_act = [8]\n",
    "            elif cir_act==4:\n",
    "                #left_act = [1]\n",
    "                left_act = [6]\n",
    "            '''    \n",
    "            #print(cir_act)\n",
    "            #print(left_act)\n",
    "            \n",
    "            '''\n",
    "            out_pos = actions_to_trajectory(traj[-1],[left_act[0]])[1]\n",
    "            ro = -out_pos[1] + y + img_dim//2\n",
    "            co = out_pos[0] - x + img_dim//2\n",
    "            if img_st[ro,co] in [1,2]:\n",
    "                cir_pos = out_pos\n",
    "                cir_act = left_act[0]\n",
    "            elif img_st[ri,ci] in [0]:\n",
    "                cir_act = righ_act[0]\n",
    "                cir_pos = actions_to_trajectory(traj[-1],[cir_act])[1]\n",
    "            '''\n",
    "                \n",
    "            out = False\n",
    "            for a in left_act:\n",
    "                new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                ro = -new_pos[1] + y + img_dim//2\n",
    "                co = new_pos[0] - x + img_dim//2\n",
    "                if img_st[ro,co] in [1]:\n",
    "                    cir_pos = new_pos\n",
    "                    cir_act = a\n",
    "                    out = True\n",
    "                    break\n",
    "                    \n",
    "            if not out:\n",
    "                for a in left_act:\n",
    "                    new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                    ro = -new_pos[1] + y + img_dim//2\n",
    "                    co = new_pos[0] - x + img_dim//2\n",
    "                    if img_st[ro,co] in [2]:\n",
    "                        cir_pos = new_pos\n",
    "                        cir_act = a\n",
    "                        out = True\n",
    "                        break\n",
    "\n",
    "            counter = 0\n",
    "            for (dr,dc) in move_neigh:\n",
    "                rn = ri + dr\n",
    "                cn = ci + dc\n",
    "                if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn] in [0]:\n",
    "                    counter += 1\n",
    "\n",
    "            if not out and img_st[ri,ci] in [0] and counter>=6:\n",
    "                for a in righ_act:\n",
    "                    new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                    cir_pos = new_pos\n",
    "                    cir_act = a\n",
    "                    \n",
    "            if np.linalg.norm(cir_pos-close_pos,2)<=1 and curr_agent > close_agent_id:\n",
    "                cir_pos = traj[-1]\n",
    "                cir_act = 0\n",
    "                    \n",
    "#             rp = -cir_pos[1] + y + img_dim//2\n",
    "#             cp = cir_pos[0] -x + img_dim//2\n",
    "#             #if img_st[rp,cp] in [0,2]:\n",
    "#             for a in left_act:\n",
    "#                 new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "#                 rl = -new_pos[1] + y + img_dim//2\n",
    "#                 cl = new_pos[0] -x + img_dim//2\n",
    "\n",
    "#                 if img_st[rl,cl] in [1]:\n",
    "#                     cir_pos = new_pos\n",
    "#                     cir_act = a\n",
    "#                     break\n",
    "                    \n",
    "            #print(cir_act)\n",
    "            #print()\n",
    "            \n",
    "            \n",
    "            \n",
    "            traj.append(cir_pos)\n",
    "            actions.append(cir_act)      \n",
    "\n",
    "        if not seen_fire:\n",
    "            dists = []\n",
    "            #for a in range(9):\n",
    "            for idx,a in enumerate([2,5,7,4,1,3,8,6]):\n",
    "                new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                incntv = -(8-idx)*0.1\n",
    "                dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1])+incntv,new_pos,a))\n",
    "                \n",
    "            #print(dists)\n",
    "            #print()\n",
    "            traj.append(min(dists)[1])\n",
    "            actions.append(min(dists)[2])\n",
    "        \n",
    "    return traj, actions, seen_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heuristic_trajectory(pos, img_st, center, close_pos, num_actions, grid_size, \n",
    "                         last_step, curr_agent, close_agent_id, seen_fire, prev_action, hdng):\n",
    "\n",
    "    traj = []\n",
    "    actions = []\n",
    "    traj.append((pos[0],pos[1]))\n",
    "    img_dim = img_st.shape[0]\n",
    "    fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "    move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "    action_set = [4,1,2,3,5,8,7,6]\n",
    "    \n",
    "    for k in range(num_actions):\n",
    "        dists = None\n",
    "        x,y = traj[k]\n",
    "\n",
    "        r = img_dim//2\n",
    "        c = img_dim//2\n",
    "        \n",
    "        if img_st[r,c] in [1,2] or seen_fire:\n",
    "            dists = []\n",
    "            seen_fire = True\n",
    "                \n",
    "            if hdng==0:\n",
    "                action_set = [1,2,3,5,8,7,6,4]\n",
    "            elif hdng==45:\n",
    "                action_set = [4,1,2,3,5,8,7,6]\n",
    "            elif hdng==90:\n",
    "                action_set = [6,4,1,2,3,5,8,7]\n",
    "            elif hdng==135:\n",
    "                action_set = [7,6,4,1,2,3,5,8]\n",
    "            elif hdng==180:\n",
    "                action_set = [8,7,6,4,1,2,3,5]\n",
    "            elif hdng==225:\n",
    "                action_set = [5,8,7,6,4,1,2,3]\n",
    "            elif hdng==270:\n",
    "                action_set = [3,5,8,7,6,4,1,2]\n",
    "            elif hdng==315:\n",
    "                action_set = [2,3,5,8,7,6,4,1]\n",
    "                \n",
    "            cir_pos = None\n",
    "            cir_act = None\n",
    "\n",
    "            for a in action_set:\n",
    "                '''\n",
    "                if prev_action==2 and a==7:\n",
    "                    continue\n",
    "                elif prev_action==3 and a==6:\n",
    "                    continue\n",
    "                elif prev_action==5 and a==4:\n",
    "                    continue\n",
    "                elif prev_action==8 and a==1:\n",
    "                    continue\n",
    "                elif prev_action==7 and a==2:\n",
    "                    continue\n",
    "                elif prev_action==6 and a==3:\n",
    "                    continue\n",
    "                elif prev_action==4 and a==5:\n",
    "                    continue\n",
    "                elif prev_action==1 and a==8:\n",
    "                    continue\n",
    "                '''\n",
    "                \n",
    "                new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                #if new_pos in prev_action:\n",
    "                #    continue\n",
    "\n",
    "                rl = -new_pos[1] + y + img_dim//2\n",
    "                cl = new_pos[0] -x + img_dim//2\n",
    "\n",
    "                if img_st[rl,cl]==0:\n",
    "                    continue\n",
    "\n",
    "                counter = 0\n",
    "                for (dr,dc) in fire_neigh:\n",
    "                    rn = rl + dr\n",
    "                    cn = cl + dc\n",
    "                    if rn>=0 and rn<img_dim and cn>=0 and cn<img_dim and img_st[rn,cn]==0:\n",
    "                        counter += 1\n",
    "\n",
    "                if counter>0:\n",
    "                    cir_pos = new_pos\n",
    "                    cir_act = a\n",
    "                    break   \n",
    "                    \n",
    "            if cir_pos is None:\n",
    "                print(pos)\n",
    "                print(img_st)\n",
    "            \n",
    "            if curr_agent > close_agent_id and np.linalg.norm(cir_pos-close_pos,2)<=1:\n",
    "                cir_pos = traj[-1]\n",
    "                cir_act = 0\n",
    "                \n",
    "                    \n",
    "            traj.append(cir_pos)\n",
    "            actions.append(cir_act)\n",
    "            \n",
    "            if cir_act==1:\n",
    "                new_hdng = 135\n",
    "            elif cir_act==2:\n",
    "                new_hdng = 90\n",
    "            elif cir_act==3:\n",
    "                new_hdng = 45\n",
    "            elif cir_act==5:\n",
    "                new_hdng = 0\n",
    "            elif cir_act==8:\n",
    "                new_hdng = 315\n",
    "            elif cir_act==7:\n",
    "                new_hdng = 270\n",
    "            elif cir_act==6:\n",
    "                new_hdng = 225\n",
    "            elif cir_act==4:\n",
    "                new_hdng = 180\n",
    "            elif cir_act==0:\n",
    "                new_hdng = hdng\n",
    "                    \n",
    "        if not seen_fire:\n",
    "            dists = []\n",
    "            #for a in range(9):\n",
    "            for idx,a in enumerate([2,5,7,4,1,3,8,6]):\n",
    "                new_pos = actions_to_trajectory(traj[-1],[a])[1]\n",
    "                incntv = -(8-idx)*0.1\n",
    "                dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1])+incntv,new_pos,a))\n",
    "                \n",
    "            #print(dists)\n",
    "            #print()\n",
    "            score,pos,act = min(dists)\n",
    "            \n",
    "            traj.append(pos)\n",
    "            actions.append(act)\n",
    "            \n",
    "            if act==1:\n",
    "                new_hdng = 135\n",
    "            elif act==2:\n",
    "                new_hdng = 90\n",
    "            elif act==3:\n",
    "                new_hdng = 45\n",
    "            elif act==5:\n",
    "                new_hdng = 0\n",
    "            elif act==8:\n",
    "                new_hdng = 315\n",
    "            elif act==7:\n",
    "                new_hdng = 270\n",
    "            elif act==6:\n",
    "                new_hdng = 225\n",
    "            elif act==4:\n",
    "                new_hdng = 180\n",
    "        \n",
    "    return traj, actions, seen_fire, new_hdng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network datatype [cpu/gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class eelfff_net(nn.Module):\n",
    "    \"\"\"\n",
    "    network to approximate Q function\n",
    "    \"\"\"\n",
    "    def __init__(self, act_seq=6, img_dim=8):\n",
    "        self.act_seq = act_seq\n",
    "        self.img_dim = img_dim\n",
    "        self.num_poss_actions = 9\n",
    "        \n",
    "        C, H, W = 1, img_dim, img_dim\n",
    "        hidden_dim = 2048\n",
    "        \n",
    "        # conv layer settings\n",
    "        nf1 = 32; nf2 = 64; nf3 = 64;\n",
    "        fs1 = 4; fs2 = 3; fs3 = 2;\n",
    "        cv_s1 = 1; cv_s2 = 1; cv_s3 = 1;\n",
    "        cv_p1 = 0; cv_p2 = 0; cv_p3 = 0;\n",
    "        \n",
    "        # pool layer settings\n",
    "        #p_sz1 = 4; p_sz2 = 2\n",
    "        #p_st1 = 1; p_st2 = 1\n",
    "        \n",
    "        # calculate affine layer size\n",
    "        Hp1 = 1 + (H + 2*cv_p1 - fs1) // cv_s1\n",
    "        Wp1 = Hp1\n",
    "        #Hpp1 = 1 + (Hp1 - p_sz1) // p_st1\n",
    "        #Wpp1 = Hpp1\n",
    "        \n",
    "        Hp2 = 1 + (Hp1 + 2*cv_p2 - fs2) // cv_s2\n",
    "        Wp2 = Hp2\n",
    "        #Hpp2 = 1 + (Hp2 - p_sz2) // p_st2\n",
    "        #Wpp2 = Hpp2\n",
    "        \n",
    "        Hp3 = 1 + (Hp2 + 2*cv_p3 - fs3) // cv_s3\n",
    "        Wp3 = Hp3        \n",
    "        \n",
    "        #aff_flat_size = nf2*Hpp2*Wpp2 + 2*act_seq\n",
    "        # image + other trajectory + center\n",
    "        aff_flat_size = nf3*Hp3*Wp3 + 2*(act_seq+1) + 2\n",
    "        \n",
    "        #print(Hp1)\n",
    "        #print(Hp2)\n",
    "        #print(Hp3)\n",
    "        \n",
    "        super(eelfff_net, self).__init__()\n",
    "        # cnn structure\n",
    "        self.cnn = nn.Sequential(\n",
    "                        nn.Conv2d(C, nf1, kernel_size=fs1, stride=cv_s1, padding=cv_p1),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(nf1, nf2, kernel_size=fs2, stride=cv_s2, padding=cv_p2),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(nf2, nf3, kernel_size=fs3, stride=cv_s3, padding=cv_p3),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        #nn.MaxPool2d(p_sz1,stride=p_st1),\n",
    "                        #nn.Conv2d(nf1, nf2, kernel_size=fs2, stride=cv_s2, padding=cv_p2),\n",
    "                        #nn.ReLU(inplace=True),\n",
    "                        #nn.MaxPool2d(p_sz2,stride=p_st2),\n",
    "                        Flatten()\n",
    "                    )\n",
    "        \n",
    "        # nonlinear structure\n",
    "        self.aff = nn.Sequential(\n",
    "                        nn.Linear(aff_flat_size, hidden_dim),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        #nn.Linear(hidden_dim, self.num_poss_actions*act_seq),\n",
    "                        nn.Linear(hidden_dim, self.num_poss_actions)\n",
    "                    )\n",
    "        \n",
    "    def forward(self, img, act, center):\n",
    "        img_exp = img.unsqueeze(0)\n",
    "        img_exp = img_exp.unsqueeze(0)\n",
    "        act_exp = act.unsqueeze(0)\n",
    "        cen_exp = center.unsqueeze(0)\n",
    "        #hsf_exp = hasfire.unsqueeze(0)\n",
    "        feat = self.cnn(img_exp)\n",
    "        feat = torch.cat((feat, act_exp, cen_exp), dim=1)\n",
    "        Q = self.aff(feat)\n",
    "        \n",
    "        #return Q.view(N,self.num_poss_actions,self.act_seq)\n",
    "        return Q.view(N,self.num_poss_actions,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test implementation of network with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic = time.clock()\n",
    "N = 1\n",
    "img_dim = 8\n",
    "act_seq = 3\n",
    "model = eelfff_net(act_seq, img_dim).type(dtype)\n",
    "\n",
    "img = torch.randn(img_dim,img_dim).type(dtype)\n",
    "act = torch.randn(2*(act_seq+1)).type(dtype)\n",
    "center = torch.randn(2).type(dtype)\n",
    "hasfire = (True*torch.ones(1)).type(dtype)\n",
    "\n",
    "img_var = Variable(img)\n",
    "act_var = Variable(act)\n",
    "center_var = Variable(center)\n",
    "# hasfire_var = Variable(hasfire)\n",
    "\n",
    "Q = model(img_var, act_var, center_var)\n",
    "toc = time.clock()\n",
    "\n",
    "print(Q.size())\n",
    "print(\"%0.2fs = %0.2fm elapsed for this test\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define a reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def eelfff_reward(states, trajs, fire_flags, other_trajs):\n",
    "#     N = len(states)\n",
    "#     grid_size = states[0].shape[0]\n",
    "#     center = math.ceil(grid_size/2)\n",
    "#     neighbors = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "#     #reward = Variable(torch.zeros(1), requires_grad=True).type(dtype)\n",
    "#     reward = 0\n",
    "    \n",
    "#     for n in range(N):\n",
    "#         st = states[n]\n",
    "#         traj = trajs[n]\n",
    "#         other_traj = other_trajs[n]\n",
    "#         has_fires = fire_flags[n]\n",
    "#         n_rew = 0\n",
    "        \n",
    "#         # reward for treating fires and boundary fires\n",
    "#         # that weren't already treated by the agent\n",
    "#         if has_fires:\n",
    "#             treated = []\n",
    "#             for (x,y) in traj:\n",
    "#                 r = y_to_row(grid_size,y)\n",
    "#                 c = x_to_col(x)\n",
    "\n",
    "#                 # reward for treating a fire\n",
    "#                 if r>=0 and r<grid_size and c>=0 and c<grid_size and st[r,c]==1 and (x,y) not in treated:\n",
    "#                     n_rew += 1\n",
    "\n",
    "#                     counter = 0 \n",
    "#                     for (dc,dr) in neighbors:\n",
    "#                         rn = r + dr\n",
    "#                         cn = c + dc\n",
    "#                         if rn>=0 and rn<grid_size and cn>=0 and cn<grid_size and st[rn,cn] == 0:\n",
    "#                             counter += 1\n",
    "\n",
    "#                     # bonus for treating a boundary fire\n",
    "#                     if counter >= 2:\n",
    "#                         n_rew += 2\n",
    "#                     #    print('treated a boundary fire')\n",
    "#                     #else:\n",
    "#                     #    print('treated a normal fire')\n",
    "                        \n",
    "#                     treated.append((x,y))\n",
    "                \n",
    "#                 elif (x,y) in treated:\n",
    "#                     n_rew += -3\n",
    "                \n",
    "#                 else:\n",
    "#                     n_rew += -1\n",
    "           \n",
    "#         # reward for approaching center [if no fires in image]\n",
    "#         else:\n",
    "#             #x_end, y_end = traj[-1]\n",
    "#             #n_rew -= np.abs(x_end-center) + np.abs(y_end-center)\n",
    "            \n",
    "#             for k in range(len(traj)-1):\n",
    "#                 x1, y1 = traj[k]\n",
    "#                 x2, y2 = traj[k+1]\n",
    "#                 #if np.abs(x2-center)+np.abs(y2-center) < np.abs(x1-center)+np.abs(y1-center):\n",
    "#                 #    reward += 1.0/(len(traj)-1)\n",
    "#                 #    #print('made it closer to the center')\n",
    "                \n",
    "#                 if np.abs(x2-center)+np.abs(y2-center) >= np.abs(x1-center)+np.abs(y1-center):\n",
    "#                     n_rew += -2\n",
    "#                 elif np.abs(x2-center)+np.abs(y2-center) < np.abs(x1-center)+np.abs(y1-center):\n",
    "#                     n_rew += 1\n",
    "    \n",
    "#         # penalty for intersecting with 'nearest agent'\n",
    "#         #if not set(traj).isdisjoint(other_traj):\n",
    "#         #    #reward += -2*len(set(traj).intersection(other_traj))\n",
    "#         #    n_rew = -4\n",
    "#         #    #print('intersected with a friends path :(')\n",
    "#         #else:\n",
    "#         #    n_rew += 0.1\n",
    "            \n",
    "#         reward += n_rew\n",
    "    \n",
    "#     return reward/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tic = time.clock()\n",
    "\n",
    "# states = np.zeros((3,5,5)).astype(np.uint8)\n",
    "# states[:,2,2] = 1\n",
    "# trajs = []\n",
    "# trajs.append([(5,5),(5,5),(4,4)])\n",
    "# trajs.append([(3,3),(3,3),(3,3)])\n",
    "# trajs.append([(5,5),(4,4),(3,3)])\n",
    "# other_trajs = []\n",
    "# other_trajs.append([(1,1),(1,2),(1,1)])\n",
    "# other_trajs.append([(1,1),(1,2),(1,3)])\n",
    "# other_trajs.append([(1,1),(2,2),(3,3)])\n",
    "# fire_flags = [False, True, True]\n",
    "\n",
    "# reward = eelfff_reward(states, trajs, fire_flags, other_trajs)\n",
    "# print('minibatch reward: %0.2f' %reward)\n",
    "\n",
    "# toc = time.clock()\n",
    "# print(\"%0.2fs = %0.2fm elapsed for this test\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eelfff_reward(state, traj, other_traj, control):\n",
    "    grid_size = state.shape[0]\n",
    "    center = math.ceil(grid_size/2)\n",
    "    fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "    move_neigh = [(-1,0),(0,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)]\n",
    "    reward = 0\n",
    "    \n",
    "    #for idx, (x,y) in traj:   \n",
    "    for k in range(len(traj)-1):\n",
    "        x1, y1 = traj[k]\n",
    "        x2, y2 = traj[k+1]\n",
    "        \n",
    "        near_fire = False\n",
    "        for (dx,dy) in move_neigh:\n",
    "            r = y_to_row(grid_size,y1+dy)\n",
    "            c = x_to_col(x1+dx)\n",
    "            \n",
    "            if r>=0 and r<grid_size and c>=0 and c<grid_size and state[r,c]==1:\n",
    "                near_fire = True\n",
    "                break\n",
    "        \n",
    "        #print(near_fire)\n",
    "        if near_fire:\n",
    "            r = y_to_row(grid_size,y2)\n",
    "            c = x_to_col(x2)\n",
    "            \n",
    "            if r>=0 and r<grid_size and c>=0 and c<grid_size and state[r,c]==1 and (x2,y2) not in control:\n",
    "                counter = 0 \n",
    "                for (dc,dr) in fire_neigh:\n",
    "                    rn = r + dr\n",
    "                    cn = c + dc\n",
    "                    if rn>=0 and rn<grid_size and cn>=0 and cn<grid_size and state[rn,cn] == 0:\n",
    "                        counter += 1\n",
    "                        \n",
    "                if counter >= 2:\n",
    "                    #print('treated boundary')\n",
    "                    reward += 0.1\n",
    "                else:\n",
    "                    #print('did not treat boundary fire')\n",
    "                    reward -= 1\n",
    "            else:\n",
    "                #print('close to fire but didnt treat it')\n",
    "                reward -= 1\n",
    "            \n",
    "        elif np.abs(x2-center)+np.abs(y2-center) < np.abs(x1-center)+np.abs(y1-center):\n",
    "            #print('moved closer to center')\n",
    "            reward += 0.1\n",
    "        else:\n",
    "            #print('failed all objectives')\n",
    "            reward -= 1\n",
    "            \n",
    "    # penalty for intersecting with 'nearest agent'\n",
    "    if not set(traj).isdisjoint(other_traj):\n",
    "        #reward += -2*len(set(traj).intersection(other_traj))\n",
    "        reward -= 1\n",
    "        #print('intersected with a friends path :(')\n",
    "    else:\n",
    "        reward += 0.1\n",
    "\n",
    "        \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic = time.clock()\n",
    "\n",
    "state = np.zeros((5,5)).astype(np.uint8)\n",
    "state[2,2] = 1\n",
    "traj = [(5,5),(5,5),(4,4),(3,3)]\n",
    "other_traj = [(1,1),(1,2),(1,1)]\n",
    "control = []\n",
    "\n",
    "reward = eelfff_reward(state, traj, other_traj, control)\n",
    "print('reward: %0.2f' %reward)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed for this test\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulator and network parameters\n",
    "grid_size = 50\n",
    "num_agents = [2,5,10]\n",
    "D = []\n",
    "memory_size = 100000\n",
    "min_exp_size = 50\n",
    "dp = 0.15/0.2763\n",
    "act_seq = 1\n",
    "act_repeat = 6\n",
    "other_act_seq = act_repeat//2\n",
    "img_dim = 8\n",
    "center = math.ceil(grid_size/2)\n",
    "cen_var = Variable(center*torch.ones(2)).type(dtype)\n",
    "\n",
    "# agent initialization parameters\n",
    "spawn_loc = np.arange(grid_size//3//2,grid_size,grid_size//3)\n",
    "perturbs = np.arange(-grid_size//3//2+1,grid_size//3//2+1,1)\n",
    "\n",
    "# create network instance\n",
    "model = eelfff_net(act_seq=act_seq, img_dim=img_dim).type(dtype)\n",
    "target = eelfff_net(act_seq=act_seq, img_dim=img_dim).type(dtype)\n",
    "updt_max = 250\n",
    "dqn_updt_cntr = 1\n",
    "\n",
    "# optimizer and its parameters\n",
    "gamma = 0.95\n",
    "# eps_init = 1\n",
    "# eps_finl = 0.1\n",
    "# epsilon = eps_init #0.15\n",
    "# anneal_range = 10000\n",
    "batch_size = 32\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_agents = [6]\n",
    "seeds = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tic = time.clock()\n",
    "# run simulator many times\n",
    "for s in seeds:\n",
    "    np.random.seed(s)\n",
    "    \n",
    "    # initialize simulator\n",
    "    sim = FireSimulator(grid_size, rng=s)\n",
    "    \n",
    "    # initialize agent positions\n",
    "    n = np.squeeze(np.random.choice(num_agents, 1))\n",
    "    agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "    agent_pos = agent_pos.astype(np.int32)\n",
    "    \n",
    "    ep_rew = 0\n",
    "    \n",
    "    control = []\n",
    "    repeat_cntr = 1\n",
    "        \n",
    "    # run to termination\n",
    "    while not sim.end:\n",
    "        \n",
    "        #control = []\n",
    "        new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "        agent_data = {}\n",
    "        #print(agent_pos)\n",
    "        \n",
    "        # generate control for each agent\n",
    "        for k in range(n):\n",
    "            agent_data[k] = {}\n",
    "            \n",
    "            # generate and save image\n",
    "            img, img_st, hasfire = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "            img_var = Variable(torch.from_numpy(img)).type(dtype)\n",
    "            hasfire_var = Variable(hasfire*torch.ones(1)).type(dtype)\n",
    "            agent_data[k]['img'] = img_var\n",
    "            agent_data[k]['hasfire'] = hasfire_var\n",
    "\n",
    "            # find nearest neighbor and their trajectory, and save it\n",
    "            dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i) for i,pos in enumerate(agent_pos) if i != k]\n",
    "            min_idx = min(dists)[1]\n",
    "            other_img, other_img_st, other_hasfire = CreateImageBW(sim.state, agent_pos[min_idx,:])\n",
    "            other_traj, _ = heuristic_trajectory(agent_pos[min_idx,:], center, \n",
    "                                                 act_seq, other_img_st, other_hasfire, control)\n",
    "            other_traj_var = Variable(torch.from_numpy(np.asarray(other_traj).reshape((-1,)))).type(dtype)\n",
    "            agent_data[k]['other_traj'] = other_traj_var\n",
    "            \n",
    "            # always use heuristic method to generate action(s)\n",
    "            # also generate trajectory\n",
    "            pos_cen_var = Variable(torch.from_numpy(agent_pos[k,:])).type(dtype) - cen_var\n",
    "            agent_data[k]['pos_cen'] = pos_cen_var\n",
    "                \n",
    "            #actions = np.random.randint(0, high=9, size=(act_seq,))\n",
    "            traj, actions = heuristic_trajectory(agent_pos[k,:], center, act_seq, img_st, hasfire, control)\n",
    "            actions = np.asarray(actions)\n",
    "                \n",
    "            agent_data[k]['actions'] = actions \n",
    "            \n",
    "            # generate control from trajectory\n",
    "            control.extend(FindGridIntersections(sim.state, traj))\n",
    "\n",
    "            # calculate and store reward for agent\n",
    "            #reward = eelfff_reward([sim.state], [traj], [hasfire], [other_traj])\n",
    "            reward = eelfff_reward(sim.state, traj, other_traj, control)\n",
    "            agent_data[k]['reward'] = reward\n",
    "            #print(reward)\n",
    "            ep_rew += reward\n",
    "                        \n",
    "            # store agent's new position\n",
    "            new_agent_pos[k,:] = [traj[-1][0], traj[-1][1]]\n",
    "            \n",
    "            #print(other_traj)\n",
    "            #print(actions)\n",
    "            #print(traj)\n",
    "            #5/0\n",
    "            \n",
    "        # remove duplicates from control sequence\n",
    "        control = list(set(control))\n",
    "        #if control:\n",
    "        #    print('control is not empty')\n",
    "        #    print(control)\n",
    "        #    5/0\n",
    "        \n",
    "        # step simulator\n",
    "        #sim.step(control, dbeta=dp)\n",
    "        if repeat_cntr % act_repeat == 0:\n",
    "            sim.step(control, dbeta=dp)\n",
    "            print(control)\n",
    "            control = []\n",
    "            repeat_cntr = 1\n",
    "        else:\n",
    "            repeat_cntr += 1\n",
    "                    \n",
    "        # update agent position\n",
    "        agent_pos = new_agent_pos\n",
    "        \n",
    "        # grab new state information and add to replay memory\n",
    "        isterminal = False\n",
    "        for k in range(n):\n",
    "            # generate and save image\n",
    "            next_img, _, next_hasfire = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "            next_img_var = Variable(torch.from_numpy(next_img)).type(dtype)\n",
    "            next_hasfire_var = Variable(next_hasfire*torch.ones(1)).type(dtype)\n",
    "            agent_data[k]['next_img'] = next_img_var\n",
    "            agent_data[k]['next_hasfire'] = next_hasfire_var\n",
    "            \n",
    "            # find nearest neighbor and their trajectory\n",
    "            dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i) for i,pos in enumerate(agent_pos) if i != k]\n",
    "            min_idx = min(dists)[1]\n",
    "            other_img, other_img_st, other_hasfire = CreateImageBW(sim.state, agent_pos[min_idx,:])\n",
    "            other_traj, _ = heuristic_trajectory(agent_pos[min_idx,:], center, \n",
    "                                                 act_seq, other_img_st, other_hasfire, control)\n",
    "            other_traj_var = Variable(torch.from_numpy(np.asarray(other_traj).reshape((-1,)))).type(dtype)\n",
    "            agent_data[k]['next_other_traj'] = other_traj_var\n",
    "            \n",
    "            next_pos_cen_var = Variable(torch.from_numpy(agent_pos[k,:])).type(dtype) - cen_var\n",
    "            agent_data[k]['next_pos_cen'] = next_pos_cen_var\n",
    "        \n",
    "            # check for terminal state\n",
    "            if sim.end:\n",
    "                isterminal = True\n",
    "                \n",
    "            D.append((agent_data[k]['img'],agent_data[k]['other_traj'],\n",
    "                      agent_data[k]['pos_cen'],agent_data[k]['hasfire'],\n",
    "                      agent_data[k]['actions'],agent_data[k]['reward'],\n",
    "                      agent_data[k]['next_img'],agent_data[k]['next_other_traj'],\n",
    "                      agent_data[k]['next_pos_cen'],agent_data[k]['next_hasfire'],\n",
    "                      isterminal))\n",
    "                \n",
    "        # create minibatch from replay memory\n",
    "        loss = 0\n",
    "        if len(D) < batch_size or len(D) < min_exp_size:\n",
    "            continue\n",
    "\n",
    "        batch_idxs = np.random.randint(0,high=len(D),size=batch_size)\n",
    "\n",
    "        # calculate loss over batch\n",
    "        # exp indices: 0-img, 1-other_traj, 2-pos_cen, 3-hasfire, 4-actions, 5-reward, \n",
    "        #              6-next_img, 7-next_other_traj, 8-next_pos_cen, 9-next_hasfire\n",
    "        #              10-isterminal\n",
    "        for idx in batch_idxs:\n",
    "            exp = D[idx]\n",
    "            # reward clipping\n",
    "            #curr_rew = np.clip(exp[5],-5,5)\n",
    "            curr_rew = exp[5]\n",
    "            tt = Variable(curr_rew*torch.ones(1),requires_grad=False).type(dtype)\n",
    "            \n",
    "            img_var = exp[0]\n",
    "            other_traj_var = exp[1]\n",
    "            pos_cen_var = exp[2]\n",
    "            hasfire_var = exp[3]\n",
    "            actions = exp[4]\n",
    "            \n",
    "            #img_var = empty_img_var\n",
    "            #other_traj_var = empty_traj_var\n",
    "            Q = model(img_var, other_traj_var, pos_cen_var, hasfire_var)[0]\n",
    "            x = Q[torch.from_numpy(actions).type(torch.cuda.LongTensor)].diag().sum()\n",
    "            #x = Q[torch.from_numpy(actions)].diag().sum()\n",
    "            \n",
    "            isterminal = exp[10]\n",
    "            if not isterminal:\n",
    "                next_img_var = exp[6]\n",
    "                next_other_traj_var = exp[7]\n",
    "                next_pos_cen_var = exp[8]\n",
    "                next_hasfire_var = exp[9]\n",
    "\n",
    "                #next_img_var = empty_img_var\n",
    "                #next_other_traj_var = empty_traj_var\n",
    "                #Q = model(next_img_var, next_other_traj_var, next_pos_cen_var, next_hasfire_var)[0]\n",
    "                Q = target(next_img_var, next_other_traj_var, next_pos_cen_var, next_hasfire_var)[0]\n",
    "                maxQ = Q.max(dim=0)[0].sum()\n",
    "                #x += gamma*maxQ\n",
    "                tt += Variable(gamma*maxQ.data, requires_grad=False).type(dtype)\n",
    "            \n",
    "            # error clipping\n",
    "            #loss += (loss_fn(x, tt)).clamp(min=-5,max=5)\n",
    "            loss += loss_fn(x, tt)\n",
    "\n",
    "        loss /= batch_size\n",
    "\n",
    "        # update network\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping\n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), 0.5) \n",
    "        #for param in model.parameters():\n",
    "        #    param.grad.data.clamp_(-1,1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # anneal exploration rate\n",
    "        #if epsilon > eps_finl:\n",
    "        #    epsilon += -(eps_init - eps_finl) / anneal_range\n",
    "        \n",
    "        # update target network, if appropriate\n",
    "        if dqn_updt_cntr % updt_max == 0:\n",
    "            target = copy.deepcopy(model)\n",
    "            dqn_updt_cntr = 1\n",
    "        else:\n",
    "            dqn_updt_cntr += 1\n",
    "        \n",
    "        # drop from memory if too many elements\n",
    "        if len(D) > memory_size:\n",
    "            D = D[len(D)-memory_size:]\n",
    "            \n",
    "        #print(agent_pos)\n",
    "        #print()\n",
    "        #5/0\n",
    "            \n",
    "    print(\"average reward: %0.2f\" %(ep_rew/(n*sim.iter)))\n",
    "    print(\"episode stats: %s, %f\" %(sim.stats,sim.stats[0]/np.sum(sim.stats)))\n",
    "        \n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network in simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_agents = [10]\n",
    "seeds = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plotting = True\n",
    "tic = time.clock()\n",
    "# run simulator many times\n",
    "for s in seeds:\n",
    "    np.random.seed(s)\n",
    "    \n",
    "    # initialize simulator\n",
    "    sim = FireSimulator(grid_size, rng=s)\n",
    "    sim.step([])\n",
    "    \n",
    "    # initialize agent positions\n",
    "    n = np.squeeze(np.random.choice(num_agents, 1))\n",
    "    agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "    agent_pos = agent_pos.astype(np.int32)\n",
    "    \n",
    "    ep_rew = 0\n",
    "    \n",
    "    control = []\n",
    "    repeat_cntr = 1\n",
    "    \n",
    "    agent_act = {}\n",
    "    agent_sf = {}\n",
    "    agent_prev = {}\n",
    "    agent_hd = {}\n",
    "    for k in range(n):\n",
    "        agent_act[k] = None\n",
    "        agent_sf[k] = False\n",
    "        agent_prev[k] = []\n",
    "        agent_hd[k] = 0\n",
    "\n",
    "    # run to termination\n",
    "    while not sim.end:\n",
    "    #for _ in range(6*10):\n",
    "        if plotting:\n",
    "            plt.figure()\n",
    "            plt.grid()\n",
    "            plt.xlim([0,grid_size+1])\n",
    "            plt.ylim([0,grid_size+1])\n",
    "            plt.title('iteration: %d, action: %d' % (sim.iter,repeat_cntr))\n",
    "\n",
    "            #plt.plot(center,center,\"gx\")\n",
    "            for i in range(grid_size):\n",
    "                for j in range(grid_size):\n",
    "                    x = col_to_x(j)\n",
    "                    y = row_to_y(grid_size,i)\n",
    "                    if sim.state[i,j] == 1:\n",
    "                        plt.plot(x,y,\"rs\",alpha=0.6)\n",
    "                    elif sim.state[i,j] == 2:\n",
    "                        plt.plot(x,y,\"ks\",alpha=0.6)\n",
    "        \n",
    "        new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "        #agent_data = {}\n",
    "        #print(agent_pos)\n",
    "        \n",
    "        # generate control for each agent\n",
    "        for k in range(n):\n",
    "            # generate image\n",
    "            img, img_st, hasfire = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "\n",
    "            # find nearest neighbor and their trajectory, and save it\n",
    "            #dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i) for i,pos in enumerate(agent_pos) if i != k]\n",
    "            #min_idx = min(dists)[1]\n",
    "            #other_img, other_img_st, other_hasfire = CreateImageBW(sim.state, agent_pos[min_idx,:])\n",
    "            #other_traj, _ = heuristic_trajectory(agent_pos[min_idx,:], other_img_st, \n",
    "            #                                        center, other_act_seq, grid_size)\n",
    "            #other_traj, _ = heuristic_trajectory(agent_pos[min_idx,:], center, \n",
    "            #                                        act_seq, other_img_st, other_hasfire, control)\n",
    "            \n",
    "            # generate actions using network\n",
    "            #pos_cen_var = Variable(torch.from_numpy(agent_pos[k,:])).type(dtype) - cen_var\n",
    "\n",
    "            #img_var = Variable(torch.from_numpy(img)).type(dtype)\n",
    "            #other_traj_var = Variable(torch.from_numpy(np.asarray(other_traj).reshape((-1,)))).type(dtype)\n",
    "            #hasfire_var = Variable(hasfire*torch.ones(1)).type(dtype)\n",
    "\n",
    "            #img_var = empty_img_var\n",
    "            #other_traj_var = empty_traj_var\n",
    "            \n",
    "            #Q = model(img_var, other_traj_var, pos_cen_var, hasfire_var)[0].data.cpu().numpy()\n",
    "            #print(Q)\n",
    "            #print(\"range of Q values: %f to %f\" %(np.amin(Q),np.amax(Q)))\n",
    "            #actions = np.argmax(Q,axis=0)\n",
    "            #traj = actions_to_trajectory(agent_pos[k,:], actions)\n",
    "            \n",
    "            #traj, actions = heuristic_trajectory(agent_pos[k,:], center, act_seq, img_st, hasfire, control)\n",
    "            #actions = np.asarray(actions)\n",
    "            \n",
    "            if agent_act[k] is None or len(agent_act[k])==0:\n",
    "                dists = [(np.linalg.norm(agent_pos[k,:]-pos,1),i) for i,pos in enumerate(agent_pos) if i!=k]\n",
    "                #min_dist = min(dists)[0]\n",
    "                min_idx = min(dists)[1]\n",
    "                #agent_pos[min_idx,:]\n",
    "                _, action_set, sf, hd = heuristic_trajectory(agent_pos[k,:], img_st, 25.5, agent_pos[min_idx,:], \n",
    "                                                             act_seq, grid_size, repeat_cntr>=act_repeat, \n",
    "                                                             k, min_idx, agent_sf[k], agent_prev[k], agent_hd[k])\n",
    "\n",
    "                #_, action_set = heuristic_trajectory(agent_pos[k,:], center, act_seq*act_repeat, \n",
    "                #                                     img_st, hasfire, control)\n",
    "                agent_act[k] = action_set\n",
    "                agent_sf[k] = sf\n",
    "                agent_hd[k] = hd\n",
    "                \n",
    "            #print(agent_act[k])\n",
    "            #print(type(agent_act[k]))\n",
    "\n",
    "            actions = [agent_act[k].pop(0)]\n",
    "            traj = actions_to_trajectory(agent_pos[k,:], actions)\n",
    "            agent_prev[k].append(traj[-1])\n",
    "            \n",
    "            # generate control from trajectory\n",
    "            control.extend(FindGridIntersections(sim.state, traj))\n",
    "            \n",
    "            #if k == 0:\n",
    "                #print(img_st)\n",
    "            if plotting:\n",
    "                plt.plot(traj[0][0],traj[0][1],\"bo\")\n",
    "                plt.plot(traj[-1][0],traj[-1][1],\"bx\")\n",
    "            #for (x,y) in traj:\n",
    "            #    plt.plot(x,y,\"bo\")\n",
    "                \n",
    "            #for (x,y) in other_traj:\n",
    "            #    plt.plot(x,y,\"b^\")\n",
    "            \n",
    "            # calculate and store reward for agent\n",
    "            #reward = eelfff_reward([sim.state], [traj], [hasfire], [other_traj])\n",
    "            reward = eelfff_reward(sim.state, traj, other_traj, control)\n",
    "            #print(reward)\n",
    "            ep_rew += reward\n",
    "                        \n",
    "            # store agent's new position\n",
    "            new_agent_pos[k,:] = [traj[-1][0], traj[-1][1]]\n",
    "            \n",
    "        # remove duplicates from control sequence\n",
    "        control = list(set(control))\n",
    "        #if control:\n",
    "        #    print('control is not empty')\n",
    "        #    print(control)\n",
    "        #    5/0\n",
    "        \n",
    "        # step simulator\n",
    "        #sim.step(control, dbeta=dp)\n",
    "        if repeat_cntr % act_repeat == 0:\n",
    "            sim.step(control, dbeta=dp)\n",
    "            control = []\n",
    "            for k in range(n):\n",
    "                agent_act[k] = None\n",
    "                agent_prev[k] = []\n",
    "            repeat_cntr = 1\n",
    "            #if sim.iter >= 3:\n",
    "            #    5/0\n",
    "        else:\n",
    "            repeat_cntr += 1\n",
    "        \n",
    "        # update agent position\n",
    "        agent_pos = new_agent_pos\n",
    "        \n",
    "        if plotting:\n",
    "            #plt.legend(['%d' %(len(set(tuple(x) for x in agent_pos)))])\n",
    "            plt.plot(25.5,25.5,\"ys\",alpha=1,label='# unique agents = %d' %(len(set(tuple(x) for x in agent_pos))))\n",
    "            plt.legend()\n",
    "            \n",
    "        #if sim.end:\n",
    "        #    print('breaking early because game ended')\n",
    "        #    break\n",
    "        \n",
    "        #if len(set(tuple(x) for x in agent_pos)) < n:\n",
    "        #    print('agents merged!')\n",
    "        #    #plt.plot(23,24,\"yo\")\n",
    "        #    break\n",
    "        \n",
    "            \n",
    "    print(\"average reward: %0.2f\" %(ep_rew/(n*sim.iter)))\n",
    "    print(\"episode stats: %s, %f\" %(sim.stats,sim.stats[0]/np.sum(sim.stats)))\n",
    "    print('# unique agents left = %d' %(len(set(tuple(x) for x in agent_pos))))\n",
    "        \n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(tuple(x) for x in agent_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
