{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/ravi/Desktop/eelfff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from FireSimulator import *\n",
    "from FireSimulatorUtilities import *\n",
    "import glob\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eelfff_reward(traj, img_st, center, close_pos, id_compare):\n",
    "    reward = 0\n",
    "    fire_neigh = [(-1,0),(0,-1),(1,0),(0,1)]\n",
    "    move_neigh = [(-1,0),(1,0),(-1,1),(0,1),(1,1),(-1,-1),(0,-1),(1,-1)] #excluded (0,0)\n",
    "    img_dim = img_st.shape[0]\n",
    "    \n",
    "    x1,y1 = traj[0]\n",
    "    x2,y2 = traj[1]\n",
    "    \n",
    "    r = -y2 + y1 + img_dim//2\n",
    "    c =  x2 - x1 + img_dim//2\n",
    "    \n",
    "    if img_st[r,c] in [1]:\n",
    "        counter = 0\n",
    "        for (dr,dc) in fire_neigh:\n",
    "            rn = r + dr\n",
    "            cn = c + dc\n",
    "            if img_st[rn,cn]==0:\n",
    "                counter += 1\n",
    "\n",
    "        if counter > 0:\n",
    "            reward += 1\n",
    "        else:\n",
    "            reward += -2\n",
    "            \n",
    "    elif img_st[r,c] in [0]:\n",
    "        counter = 0\n",
    "        for (dr,dc) in move_neigh:\n",
    "            rn = r + dr\n",
    "            cn = c + dc\n",
    "            if img_st[rn,cn] in [1,2]:\n",
    "                counter += 1\n",
    "            \n",
    "        if counter > 0:\n",
    "            reward += 0.5\n",
    "        else:\n",
    "            reward += -1\n",
    "            \n",
    "    #if np.linalg.norm(cir_pos-close_pos,2)<=1 and agent_id > close_agent_id:\n",
    "    if id_compare and np.linalg.norm(traj[1]-close_pos,2)<=1: \n",
    "        reward += -10\n",
    "    elif id_compare and np.linalg.norm(traj[0]-close_pos,2)<=1 and np.linalg.norm(traj[1]-close_pos,2)>1:\n",
    "        reward += 1\n",
    "            \n",
    "    move_vec = np.array([x2-x1,y2-y1])\n",
    "    if (x2-x1) != 0 and (y2-y1) != 0:\n",
    "        move_vec = move_vec / np.linalg.norm(move_vec,2)\n",
    "       \n",
    "    cen_vec = np.array([x1-center,y1-center])\n",
    "    cen_vec = cen_vec / np.linalg.norm(cen_vec,2)\n",
    "    score = -1*np.cross(cen_vec,move_vec)\n",
    "    \n",
    "    #reward += np.max([score,0])/score + 2*np.min([score,0])\n",
    "    if score >= 0:\n",
    "        reward += 1\n",
    "    #else:\n",
    "    #    reward += -2\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class eelfff(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_dim=8):\n",
    "        super(eelfff, self).__init__()\n",
    "        self.img_dim = img_dim\n",
    "        \n",
    "        # inputs: image + rot vec + id compare + pos-other_pos\n",
    "        self.net = nn.Sequential(\n",
    "                                nn.Linear(self.img_dim**2 + 2 + 1 + 2, 2048),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(2048, 2048),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(2048, 9)\n",
    "                            )\n",
    "\n",
    "    def forward(self, feat):\n",
    "        return self.net(feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 9])\n",
      "396.41s = 6.61m elapsed for this test\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "N = 4\n",
    "img_dim = 3\n",
    "\n",
    "model = eelfff(img_dim).type(dtype)\n",
    "feat = Variable(torch.randn(N,img_dim**2+2+1+2)).type(dtype)\n",
    "Q = model(feat)\n",
    "toc = time.clock()\n",
    "\n",
    "print(Q.size())\n",
    "print(\"%0.2fs = %0.2fm elapsed for this test\" %(toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dim = 3\n",
    "model = eelfff(img_dim=img_dim).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/home/ravi/Desktop/eelfff/networks/simple_ext-26-Aug-2017-15:17.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(filename)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark network solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "num_agents = 10\n",
    "base_station = np.array([5,5])\n",
    "\n",
    "capacity = 10\n",
    "\n",
    "fire_init = None\n",
    "# x = math.ceil(grid_size / 2)\n",
    "# deltas = [q for q in range(-5,5,1)]\n",
    "# neighbors = itertools.product(deltas,deltas)\n",
    "# for (dx,dy) in neighbors:\n",
    "#     xn = x + dx\n",
    "#     yn = x + dy\n",
    "#     fire_init.append((xn,yn))\n",
    "\n",
    "dp = 0.15/0.2763\n",
    "repeat_lim = 6\n",
    "center = (grid_size+1)/2\n",
    "spawn_loc = np.arange(grid_size//3//2,grid_size,grid_size//3)\n",
    "perturbs = np.arange(-grid_size//3//2+1,grid_size//3//2+1,1)\n",
    "\n",
    "seeds = [1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-02-21 19:32:38] start\n",
      "[2018-02-21 19:32:38] finish\n",
      "11.09s = 0.18m elapsed\n"
     ]
    }
   ],
   "source": [
    "st = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('[%s] start' % st)\n",
    "\n",
    "tic = time.clock()\n",
    "for i,s in enumerate(seeds):\n",
    "    np.random.seed(1000+s)\n",
    "    results[i] = {}\n",
    "\n",
    "    # initialize simulator\n",
    "    if fire_init is None:\n",
    "        sim = FireSimulator(grid_size, rng=s)\n",
    "        sim.step([]) # start fire in domain\n",
    "    else:\n",
    "        sim = FireSimulator(grid_size, rng=s, fire_init=fire_init)\n",
    "    \n",
    "    num_init_fires = len(sim.fires)\n",
    "\n",
    "    # initialize agent position\n",
    "    n = num_agents\n",
    "    agent_steps = 0\n",
    "    agent_pos = np.random.choice(spawn_loc, (n,2)) + np.random.choice(perturbs, (n,2))\n",
    "    agent_pos = np.squeeze(agent_pos).astype(np.int32)\n",
    "    agent_data = {}\n",
    "    for k in range(n):\n",
    "        agent_data[k] = {}\n",
    "        agent_data[k]['sf'] = False\n",
    "        agent_data[k]['cap'] = capacity\n",
    "        agent_data[k]['reward'] = 0\n",
    "        agent_data[k]['rewardsteps'] = 0\n",
    "    \n",
    "    control = []\n",
    "    repeat_ctr = 1\n",
    "\n",
    "    new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "\n",
    "    while not sim.end:        \n",
    "        # calculate action for each agent\n",
    "        for k in range(num_agents):\n",
    "            img, img_st, _ = CreateImageBW(sim.state, agent_pos[k,:])\n",
    "            if img_st[8//2,8//2] in [1,2]:\n",
    "                agent_data[k]['sf'] = True                \n",
    "\n",
    "            dists = [(np.linalg.norm(agent_pos[k,:]-p,2),j,p) for j,p in enumerate(agent_pos) if j!=k]\n",
    "            min_dist, min_id, min_pos = min(dists)                \n",
    "                \n",
    "            if not agent_data[k]['sf']:\n",
    "                \n",
    "                dists = []\n",
    "                for idx,a in enumerate([2,5,7,4,1,3,8,6]):\n",
    "                    new_pos = actions_to_trajectory(agent_pos[k,:],[a])[1]\n",
    "                    incntv = -(8-idx)*0.1\n",
    "                    dists.append((np.abs(center-new_pos[0])+np.abs(center-new_pos[1])+incntv,new_pos,a))\n",
    "\n",
    "                score, pos, action = min(dists)\n",
    "                traj = actions_to_trajectory(agent_pos[k,:], [action])\n",
    "\n",
    "            else:\n",
    "                rot_vec = agent_pos[k,:] - center\n",
    "                rot_vec = rot_vec / np.linalg.norm(rot_vec,2)\n",
    "                rot_vec = np.array([rot_vec[1],-rot_vec[0]])\n",
    "\n",
    "                pos_vec = agent_pos[k,:] - min_pos\n",
    "                if pos_vec[0]!=0 and pos_vec[1]!= 0:\n",
    "                    pos_vec = pos_vec / np.linalg.norm(pos_vec,2)\n",
    "\n",
    "                state = np.concatenate((img[3:6,3:6].reshape((img_dim**2,)), rot_vec, \n",
    "                                        np.asarray(k>min_id)[np.newaxis], pos_vec))\n",
    "            \n",
    "                state = Variable(torch.from_numpy(state)).type(dtype)\n",
    "                Q = model(state.unsqueeze(0))[0].data.cpu().numpy()\n",
    "                action = np.argmax(Q)\n",
    "                traj = actions_to_trajectory(agent_pos[k,:], [action])\n",
    "\n",
    "            if agent_data[k]['sf']:\n",
    "                reward = eelfff_reward(traj, img_st, center, min_pos, k>min_id)\n",
    "                agent_data[k]['reward'] += reward\n",
    "                agent_data[k]['rewardsteps'] += 1\n",
    "            \n",
    "            # generate control from trajectory\n",
    "            # account for capacity constraint\n",
    "            agent_control = FindGridIntersections(sim.state, traj)\n",
    "            for el in agent_control:\n",
    "                agent_data[k]['cap'] -= 1\n",
    "                control.extend([el]) \n",
    "                if agent_data[k]['cap'] <= 0:\n",
    "                    break\n",
    "                    \n",
    "            control = list(set(control))\n",
    "\n",
    "            # update agent location\n",
    "            if agent_data[k]['cap'] <= 0:\n",
    "                agent_data[k]['sf'] = False\n",
    "                agent_data[k]['cap'] = capacity\n",
    "                new_agent_pos[k,:] = base_station\n",
    "            else:\n",
    "                new_agent_pos[k,:] = [traj[-1][0], traj[-1][1]]\n",
    "                \n",
    "        # update simulator periodically \n",
    "        if repeat_ctr % repeat_lim == 0:\n",
    "            sim.step(control, dbeta=dp)\n",
    "            control = []\n",
    "        repeat_ctr += 1\n",
    "        \n",
    "        agent_steps += 1\n",
    "\n",
    "        # update agent position\n",
    "        agent_pos = new_agent_pos\n",
    "        new_agent_pos = np.zeros((n,2)).astype(np.int32)\n",
    "\n",
    "    if (i+1) % 10 == 0:\n",
    "        st = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"[%s] finished %d simulations\" % (st,i+1))\n",
    "    \n",
    "    # store simulation result\n",
    "    results[i]['frac_healthy'] = sim.stats[0]/np.sum(sim.stats)  # fraction of healthy trees\n",
    "    results[i]['totalsteps'] = sim.iter\n",
    "    results[i]['agentsteps'] = agent_steps\n",
    "    for k in range(num_agents):\n",
    "        results[i][k] = {}\n",
    "        results[i][k]['reward'] = agent_data[k]['reward']\n",
    "        results[i][k]['rewardsteps'] = agent_data[k]['rewardsteps']\n",
    "    \n",
    "datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('[%s] finish' % st)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"%0.2fs = %0.2fm elapsed\" % (toc-tic,(toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('simple_ext_capped_g%d+a%d+f%d+s%d.pkl' %(grid_size,num_agents,num_init_fires,len(seeds)), 'wb') as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: {'reward': 1375.0, 'rewardsteps': 941},\n",
       "  1: {'reward': 1327.0, 'rewardsteps': 924},\n",
       "  2: {'reward': 1314.0, 'rewardsteps': 956},\n",
       "  3: {'reward': 1381.5, 'rewardsteps': 941},\n",
       "  'frac_healthy': 0.026800000000000001,\n",
       "  5: {'reward': 1390.5, 'rewardsteps': 936},\n",
       "  6: {'reward': 1343.0, 'rewardsteps': 960},\n",
       "  7: {'reward': 1285.0, 'rewardsteps': 953},\n",
       "  8: {'reward': 1244.0, 'rewardsteps': 955},\n",
       "  9: {'reward': 1196.5, 'rewardsteps': 949},\n",
       "  'agentsteps': 1026,\n",
       "  4: {'reward': 1380.0, 'rewardsteps': 947},\n",
       "  'totalsteps': 172}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_init is None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
